{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk1_ib2G7E5j"
   },
   "source": [
    "# **Github Links**\n",
    "\n",
    "**SqueezeDet**\n",
    "https://github.com/BichenWuUCB/squeezeDet\n",
    "\n",
    "**RefinedetLite**\n",
    "https://github.com/ouyanghuiyu/RefinedetLite.pytorch\n",
    "\n",
    "**ssdlite mobilenet v2**\n",
    "https://github.com/qfgaohao/pytorch-ssd\n",
    "\n",
    "https://github.com/tranleanh/MobileNets-SSD-PyTorch\n",
    "\n",
    "https://github.com/shaoshengsong/MobileNetV3-SSD\n",
    "\n",
    "**Controllable Invariance**\n",
    "https://github.com/qizhex/Controllable-Invariance\n",
    "\n",
    "* While Yolo has fixed grid cell aspect ratio. SSD uses different aspect ratio with multi boxes for better accuracy.\n",
    "\n",
    "* SSD has additional conv layers at the end of the base mobilenet for object detection. convolutional layer has multiple features with different scale and hence it is able to detect objects in multiple scales better\n",
    "\n",
    "\n",
    "Folder: https://drive.google.com/drive/u/1/folders/1trRWtHV_io4EDScepki1Q1RS_YewKdTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yL_TDhI45u7q",
    "outputId": "f5546235-39aa-4538-d109-b623a5d8ffa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n",
      "Found GPU at: cuda:0\n",
      "/bin/bash: /opt/bin/nvidia-smi: No such file or directory\n",
      "root        1027  0.0  0.0  39304 20304 ?        Ss    2021   0:00 /usr/bin/python3 /usr/bin/networkd-dispatcher --run-startup-triggers\n",
      "root        1166  0.0  0.0 118120 22992 ?        Ssl   2021   0:00 /usr/bin/python3 /usr/share/unattended-upgrades/unattended-upgrade-shutdown --wait-for-signal\n",
      "hjchris     2788  0.1  0.1 343248 150972 ?       Sl    2021  11:19 /home/hjchris/research/mitigating/.venv/bin/python /home/hjchris/research/mitigating/.venv/bin/jupyter-notebook --no-browser --port=8888\n",
      "hjchris    16710  0.0  0.0 902444 94368 ?        Ssl   2021   0:31 /home/hjchris/research/mitigating/.venv/bin/python -m ipykernel_launcher -f /home/hjchris/.local/share/jupyter/runtime/kernel-86170f7f-479f-4d41-93c0-1f2fed830e35.json\n",
      "hjchris   465203 27.2  4.8 24052684 6409100 ?    Ssl  10:15  11:55 /home/hjchris/research/mitigating/.venv/bin/python -m ipykernel_launcher -f /home/hjchris/.local/share/jupyter/runtime/kernel-0ad89c5a-66a0-4941-9f2c-f342d19558fc.json\n",
      "hjchris   465409 84.5  0.3 14493032 430160 ?     Ssl  10:58   0:10 /home/hjchris/research/mitigating/.venv/bin/python -m ipykernel_launcher -f /home/hjchris/.local/share/jupyter/runtime/kernel-0d89be48-8864-4995-977f-2a5be61b6b32.json\n",
      "hjchris   465487 74.0  0.0   9500  3156 pts/4    Ss+  10:59   0:00 /bin/bash -c ps -aux|grep python\n",
      "hjchris   465489  0.0  0.0   9040   660 pts/4    S+   10:59   0:00 grep python\n",
      "\n",
      "Real Time: ['0102_22']\n",
      "today: 0102_22\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import progressbar\n",
    "from time import sleep\n",
    "\n",
    "from six.moves import xrange\n",
    "import threading\n",
    "\n",
    "import gc \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import collections\n",
    "from collections import deque\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import random\n",
    "import copy\n",
    "import cv2\n",
    "import itertools\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%time\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Found GPU at: {}'.format(device))\n",
    "\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# mount gdrive and confrim that dataset exists in this directory\n",
    "!/opt/bin/nvidia-smi\n",
    "!ps -aux|grep python\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "root_path = f\"/home/hjchris/research/mitigating\"\n",
    "sys.path.append(f\"/home/hjchris/repo/pytorch-ssd-master\")\n",
    "\n",
    "from datetime import date\n",
    "today = !date +\"%m%d_%y\"\n",
    "print(f\"\\nReal Time: {today}\")\n",
    "today = today[0]\n",
    "print(f\"today: {today}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frijxnVsVYls",
    "outputId": "b8e4ddee-8a24-48ec-d4d9-36de8091993f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: /home/hjchris/research/mitigating/chris/pascal_ckpts/0102_22\n",
      "File Name: 0102_22-1.log\n",
      "logging filename: /home/hjchris/research/mitigating/chris/pascal_ckpts/0102_22/0102_22-1.log\n"
     ]
    }
   ],
   "source": [
    "file_item=1\n",
    "logging_folder = f'{root_path}/chris/pascal_ckpts/{today}'\n",
    "logging_filename = f\"{today}-{file_item}.log\"\n",
    "\n",
    "if not os.path.isdir(logging_folder):\n",
    "    os.mkdir(logging_folder)\n",
    "    print(f\"Created directory: {logging_folder}\")\n",
    "\n",
    "while os.path.exists(os.path.join(logging_folder, logging_filename)):\n",
    "    file_item += 1\n",
    "    logging_filename = f\"{today}-{file_item}.log\"\n",
    "\n",
    "print(f\"File Name: {logging_filename}\")\n",
    "print(f\"logging filename: {logging_folder}/{logging_filename}\")\n",
    "\n",
    "# basicConfig = logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s' )\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "streamHandler = logging.StreamHandler(sys.stdout)\n",
    "streamHandler.setFormatter(formatter)\n",
    "\n",
    "fileHandler=logging.FileHandler(\"{0}/{1}\".format(logging_folder, logging_filename))\n",
    "fileHandler.setFormatter(formatter)\n",
    "\n",
    "train_log = logging.getLogger(\"train\")\n",
    "train_log.setLevel(logging.INFO)\n",
    "if train_log.hasHandlers(): \n",
    "    train_log.removeHandler(fileHandler)\n",
    "    train_log.removeHandler(streamHandler)\n",
    "train_log.addHandler(fileHandler)\n",
    "train_log.addHandler(streamHandler)\n",
    "\n",
    "log_dir='/home/hjchris/research/mitigating/chris/pascal_ckpts/evaluations'\n",
    "inf_log = logging.getLogger(\"Inference\")\n",
    "inf_log.setLevel(logging.INFO)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwV0YQFplUlc"
   },
   "source": [
    "Customized functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AL_mgNQaS5_r"
   },
   "outputs": [],
   "source": [
    "from vision.utils.misc import str2bool, Timer, freeze_net_layers, store_labels\n",
    "from vision.ssd.ssd import MatchPrior\n",
    "from vision.datasets.voc_dataset import VOCDataset\n",
    "from vision.nn.multibox_loss import MultiboxLoss\n",
    "from vision.utils import box_utils, measurements\n",
    "\n",
    "from vision.ssd.config import vgg_ssd_config\n",
    "from vision.ssd.config import mobilenetv1_ssd_config\n",
    "from vision.ssd.config import squeezenet_ssd_config\n",
    "from vision.ssd.data_preprocessing import TrainAugmentation, TestTransform\n",
    "\n",
    "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd\n",
    "from vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite\n",
    "from vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite\n",
    "# from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETwg6wSbgKZG"
   },
   "source": [
    "https://discuss.pytorch.org/t/how-to-load-all-data-into-gpu-for-training/27609/5\n",
    "dataloader GPU\n",
    "\n",
    "pin_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Q-hyvW5iilb"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eerhHnKXoXQa"
   },
   "source": [
    "5011, 4952\n",
    "Guess: the data originally loaded to DISK. However, for some reasons when they are loaded to RAM the second time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DCbu1IFbLEqD"
   },
   "outputs": [],
   "source": [
    "class Data_Preprocessing:\n",
    "    def __init__(self, log=print):\n",
    "\n",
    "        self.widgets = [' [',progressbar.Timer(), '] ', progressbar.Percentage(),\n",
    "            progressbar.Bar('#'),' (', \n",
    "            progressbar.ETA(), ') ', \n",
    "            ] \n",
    "        self.reset()\n",
    "        self.log = log\n",
    "        \n",
    "    def reset(self):\n",
    "        self.train_data = []\n",
    "        self.train_loader = []\n",
    "        self.valid_data = []\n",
    "        self.val_loader = []\n",
    "        \n",
    "        self.image = 0\n",
    "        self.boxes = 0\n",
    "        self.labels = 0\n",
    "\n",
    "    def add_labels(self):  \n",
    "        animal_list = [3,8,10,12,13,17] \n",
    "        vehicle_list = [1,2,4,6,7,14,19] \n",
    "        indoor_list = [5,9,11,16,18,20]\n",
    "        class_list = animal_list + indoor_list\n",
    "        class_list = [15]\n",
    "        print(f\"Labels:\\nAnimal: {animal_list}\\nVehicle:{vehicle_list}\\nIndoor: {indoor_list}\\n\")\n",
    "\n",
    "        if (valid_data != [] and len(valid_data[0]) == 3) or (train_data != [] and len(train_data[0]) == 3):\n",
    "            \n",
    "            if valid_data != []:\n",
    "                \n",
    "                labels_dis = []\n",
    "                label_sum = 0\n",
    "\n",
    "                for i, data in enumerate(valid_data):\n",
    "                    image, boxes, labels = data\n",
    "                    if any(items in labels.unique() for items in class_list):\n",
    "                        labels_dis.append(1)\n",
    "                        label_sum += 1\n",
    "                    else:\n",
    "                        labels_dis.append(0)\n",
    "\n",
    "                for i in range(len(labels_dis)):\n",
    "                    valid_data[i].append(torch.tensor(labels_dis[i]))\n",
    "\n",
    "                self.log(f\"[Valid] Contains any labels {class_list}: {label_sum/len(valid_data)*100:.2f}% is 1.\")\n",
    "                # valid_data = ConcatDataset([valid_data])\n",
    "            \n",
    "\n",
    "            if train_data != []:\n",
    "\n",
    "                labels_dis = []\n",
    "                label_sum = 0\n",
    "\n",
    "                for i, data in enumerate(train_data):\n",
    "                    image, boxes, labels = data\n",
    "                    if any(items in labels.unique() for items in class_list):\n",
    "                        labels_dis.append(1)\n",
    "                        label_sum += 1\n",
    "                    else:\n",
    "                        labels_dis.append(0)\n",
    "\n",
    "                for i in range(len(labels_dis)):\n",
    "                    train_data[i].append(torch.tensor(labels_dis[i]))\n",
    "\n",
    "                self.log(f\"[Train] Contains any labels {class_list}: {label_sum/len(train_data)*100:.2f}% is 1.\")   \n",
    "                labels_dis = []        \n",
    "                train_data = ConcatDataset([train_data])\n",
    "\n",
    "            self.log(f\"Added discrimintaor labels: {class_list}.\")\n",
    "            \n",
    "\n",
    "        self.batch_size = 16\n",
    "        if train_data != []:\n",
    "            train_loader = DataLoader(train_data, self.batch_size, shuffle=True, num_workers=4)\n",
    "            self.log(f\"Create train DataLoader from preprocessed data.\")\n",
    "        if valid_data != []:\n",
    "            val_loader = DataLoader(valid_data, self.batch_size, shuffle=False, num_workers=4)\n",
    "            self.log(f\"Create valid DataLoader from preprocessed data.\")\n",
    "        self.log(f\"DataLoader bathsize = {self.batch_size}. Discriminator label {class_list} is already loaded. Loaded data to DataLoaders.\")\n",
    "\n",
    "\n",
    "    def load_online(self, root_path, training = True, validating = True, batch_size = 32, enable_shuffle=True):\n",
    "        \n",
    "        self.reset()\n",
    "        self.batch_size = batch_size\n",
    "        self.enable_shuffle = enable_shuffle\n",
    "\n",
    "        #if self.logger: logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        self.log(f\"Using Original VOCdataset functions? Training:{training}, Testing:{validating}.\")\n",
    "\n",
    "        if training:\n",
    "            timer = Timer()\n",
    "            #  Augmentation/tranformation functions\n",
    "            dataset_paths = [root_path + '/Pascal_VOC/VOC2012', root_path +'/Pascal_VOC/VOC2007']\n",
    "            config = mobilenetv1_ssd_config\n",
    "            train_transform = TrainAugmentation(config.image_size, config.image_mean, config.image_std)\n",
    "            target_transform = MatchPrior(config.priors, config.center_variance, config.size_variance, 0.5)\n",
    "\n",
    "            # Prepare Training Data\n",
    "            self.log(f\"Prepare training datasets\")\n",
    "            datasets = []\n",
    "            datasets_attack = []\n",
    "\n",
    "            for dp in dataset_paths:\n",
    "                #  VOCDataset will pass the images into the transformation functions when pulling out the image. Dataset contains [image, boxes, labels]\n",
    "                dataset = VOCDataset(dp, transform=train_transform, target_transform=target_transform)\n",
    "                dataset_attack = VOCDataset(dp, transform=train_transform, target_transform=target_transform, is_attack=True)\n",
    "\n",
    "                label_file = os.path.join(dp, \"voc-model-labels.txt\")\n",
    "                store_labels(label_file, dataset.class_names)\n",
    "                num_classes = len(dataset.class_names)\n",
    "                datasets.append(dataset)\n",
    "                datasets_attack.append(dataset_attack)\n",
    "\n",
    "            # Store labels\n",
    "            self.log(f\"Stored labels into file.\")\n",
    "            self.train_dataset = ConcatDataset(datasets)\n",
    "            self.train_dataset_attack = ConcatDataset(datasets_attack)\n",
    "            self.train_loader = DataLoader(self.train_dataset, self.batch_size, shuffle=self.enable_shuffle, num_workers=4)\n",
    "            self.train_loader_attack = DataLoader(self.train_dataset_attack, self.batch_size, shuffle=self.enable_shuffle, num_workers=4)\n",
    "            self.log(f\"Train data: {len(self.train_dataset)}, loader: {len(self.train_loader)}, batch_size={self.batch_size}, shuffle={self.enable_shuffle}\")\n",
    "            self.log(f\"Train attack data : {len(self.train_dataset_attack)}, loader: {len(self.train_loader_attack)}, batch_size={self.batch_size}, shuffle={self.enable_shuffle}\")\n",
    "\n",
    "        if validating:\n",
    "            #if self.logger: logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "            timer = Timer()\n",
    "\n",
    "            #  Augmentation/tranformation functions\n",
    "            dataset_paths = [root_path +'/Pascal_VOC/VOC2007' ,root_path + '/Pascal_VOC/VOC2012']\n",
    "            validation_dataset_path = root_path + '/Pascal_VOC/VOC2007'\n",
    "            config = mobilenetv1_ssd_config\n",
    "            target_transform = MatchPrior(config.priors, config.center_variance, config.size_variance, 0.5)\n",
    "            test_transform = TestTransform(config.image_size, config.image_mean, config.image_std)\n",
    "            \n",
    "            # Prepare Validation Data \n",
    "            self.log(\"Prepare Validation datasets.\")\n",
    "            self.valid_data = VOCDataset(validation_dataset_path, transform=test_transform, target_transform=target_transform, is_test=True)\n",
    "            self.valid_data_attack = VOCDataset(validation_dataset_path, transform=test_transform, target_transform=target_transform, is_test=True, is_attack=True)\n",
    "            self.val_loader = DataLoader(self.valid_data, self.batch_size, shuffle=False, num_workers=4)\n",
    "            self.val_loader_attack = DataLoader(self.valid_data_attack, self.batch_size, shuffle=False, num_workers=4)\n",
    "            self.log(f\"Valid data: {len(self.valid_data)}, loader: {len(self.val_loader)}, batch_size={self.batch_size}, shuffle=False.\")\n",
    "            self.log(f\"Valid attack data: {len(self.valid_data_attack)}, loader:{len(self.val_loader_attack)}, batch_size={self.batch_size}, shuffle=False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qZ2Gqqo35Iq"
   },
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywX0OvpBFfKy"
   },
   "source": [
    "## SSD\n",
    "one-class classification: https://www.cnblogs.com/fengfenggirl/p/One-Class-Learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fS5L7FCvu1ms"
   },
   "source": [
    "1. 14th feature map of mobilnet detects 2166 objects --> feature map size is [576,19,19] --> gird cell = 19x19 (considered small grid) \n",
    "2. last feature map of mobilenet detects 600 object --> feature map size is [1280,10,10] --> gird cell = 10x10 (considered small grid) \n",
    "3. 1st extra layer detects 150 objects --> feature map size is [512,5,5] --> gird cell = 5x5\n",
    "4. 2nd extra layer detects 54 objects --> feature map size is [256,3,3] --> gird cell = 3x3\n",
    "5. 3rd extra layer detects 24 objects --> feature map size is [256,2,2] --> gird cell = 2x2\n",
    "6. 4th extra layer detects 6 objects --> feature map size is [64,1,1] --> gird cell = 1x1\n",
    " \n",
    "\n",
    "\n",
    "total: 2166+600+150+54+24+6 = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RdBLcqTmqmu6"
   },
   "outputs": [],
   "source": [
    "def dec_wrapper(norm):\n",
    "    def hook_func(grad):\n",
    "        norm.append(math.pow(grad.norm().data[0], 2))\n",
    "        pass\n",
    "    return hook_func\n",
    "\n",
    "def adv_wrapper(norm = [], grad_scale = 2):\n",
    "    def hook_func(grad):\n",
    "        new_grad = -grad * gamma\n",
    "        norm.append(math.pow(new_grad.norm().data, 2))\n",
    "        return new_grad\n",
    "        pass\n",
    "    return hook_func\n",
    "\n",
    "def adv_hook_func(grad):\n",
    "    new_grad = -grad * 2\n",
    "    return new_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KleqnDfKVI5v"
   },
   "outputs": [],
   "source": [
    "from vision.utils import box_utils\n",
    "from collections import namedtuple\n",
    "\n",
    "GraphPath = namedtuple(\"GraphPath\", ['s0', 'name', 's1'])  \n",
    "class SSD(nn.Module):\n",
    "    def __init__(self, num_classes: int, base_net: nn.ModuleList, source_layer_indexes: List[int], extras: nn.ModuleList, \n",
    "                 classification_headers: nn.ModuleList, regression_headers: nn.ModuleList,\n",
    "                 encoder_headers: nn.ModuleList, is_test=False, config=None\n",
    "                 ):\n",
    "        \"\"\"Compose a SSD model using the given components.\n",
    "        feature_map = -3: discriminator connecting to raw images X.\n",
    "        feature_map = -1: adding extra layers as encoder.\n",
    "        \"\"\"\n",
    "        super(SSD, self).__init__()\n",
    "\n",
    "        # SSD parameters\n",
    "        self.num_classes = num_classes\n",
    "        self.base_net = base_net\n",
    "        self.source_layer_indexes = source_layer_indexes\n",
    "        self.extras = extras\n",
    "        self.classification_headers = classification_headers\n",
    "        self.regression_headers = regression_headers\n",
    "        self.config = config\n",
    "\n",
    "        # outputs\n",
    "        self.output_reset()\n",
    "\n",
    "        # register layers in source_layer_indexes by adding them to a module list\n",
    "        self.source_layer_add_ons = nn.ModuleList([t[1] for t in source_layer_indexes if isinstance(t, tuple) and not isinstance(t, GraphPath)])\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.is_inference = is_test\n",
    "        \n",
    "        if self.is_inference:\n",
    "            self.config = config\n",
    "            self.priors = config.priors.to(self.device)\n",
    "            self.eval()\n",
    "\n",
    "        # Encoder \n",
    "        self.encoder_headers = encoder_headers\n",
    "\n",
    "    def output_reset(self):  \n",
    "        \n",
    "        self.confidences = []\n",
    "        self.locations = []\n",
    "\n",
    "    def forward(self, x: torch.Tensor, discriminator_loc) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        self.output_reset()\n",
    "        discriminator_loc = discriminator_loc\n",
    "        start_layer_index = 0\n",
    "        header_index = 0\n",
    "        dis_index = 0\n",
    "\n",
    "        # ======================================================================\n",
    "        # [Base net] Mobilenetv2\n",
    "        # ======================================================================\n",
    "        for end_layer_index in self.source_layer_indexes:\n",
    "\n",
    "            #  Continue to a feature layer INDEX (end_layer_index)\n",
    "            if isinstance(end_layer_index, GraphPath):\n",
    "                path = end_layer_index\n",
    "                end_layer_index = end_layer_index.s0\n",
    "                added_layer = None\n",
    "            elif isinstance(end_layer_index, tuple):\n",
    "                added_layer = end_layer_index[1]\n",
    "                end_layer_index = end_layer_index[0]\n",
    "                path = None\n",
    "            else:\n",
    "                added_layer = None\n",
    "                path = None\n",
    "\n",
    "            #  Go to that feature layer of the index (from basenet --> mobilenet)\n",
    "            for layer in self.base_net[start_layer_index: end_layer_index]:\n",
    "                if (dis_index < 18 and dis_index == discriminator_loc):\n",
    "                    if dis_index == 0:\n",
    "                        x = layer(x)\n",
    "                        z = x\n",
    "                    else:\n",
    "                        sub = getattr(self.base_net[dis_index], 'conv')\n",
    "                        for sublayer in sub[:3]:\n",
    "                            x = sublayer(x)\n",
    "                        z = x\n",
    "                        for sublayer in sub[3:]:\n",
    "                            x = sublayer(x)         \n",
    "                else:\n",
    "                    x = layer(x)\n",
    "\n",
    "                if dis_index < 18:\n",
    "                    dis_index += 1\n",
    "                \n",
    "            # if there is any added layers\n",
    "            y = added_layer(x) if added_layer else x\n",
    "\n",
    "            #  Block 14\n",
    "            if path:\n",
    "                sub = getattr(self.base_net[end_layer_index], path.name)\n",
    "                for layer in sub[:path.s1]:\n",
    "                    x = layer(x)\n",
    "                y = x\n",
    "                for layer in sub[path.s1:]:\n",
    "                    x = layer(x)\n",
    "                end_layer_index += 1\n",
    "            \n",
    "            if dis_index == discriminator_loc: z = y\n",
    "                \n",
    "            #  Block 14 and Block 18 to Predictor\n",
    "            start_layer_index = end_layer_index\n",
    "            confidence, location = self.compute_header(header_index, y)\n",
    "            self.confidences.append(confidence)\n",
    "            self.locations.append(location)\n",
    "\n",
    "            #  Discriminator for the current feature (now only for the first feature)  \n",
    "            dis_index += 1\n",
    "            header_index += 1\n",
    "        \n",
    "        # ======================================================================\n",
    "        #  Go through the rest of the basnet if any--> mobilenet \n",
    "        # ======================================================================\n",
    "        for layer in self.base_net[end_layer_index:]:\n",
    "            x = layer(x)\n",
    "\n",
    "        # ======================================================================\n",
    "        # Extra layers\n",
    "        # ======================================================================\n",
    "        # Use extra layer features to compute the confidence and location\n",
    "        for layer in self.extras:\n",
    "            x = layer(x)\n",
    "            confidence, location = self.compute_header(header_index, x)\n",
    "            self.confidences.append(confidence)\n",
    "            self.locations.append(location)\n",
    "            \n",
    "            if dis_index == discriminator_loc: z = x\n",
    "\n",
    "            #  Discriminator for the extra features (now only for the first feature)\n",
    "            dis_index += 1\n",
    "            header_index += 1\n",
    "            \n",
    "        # ======================================================================\n",
    "        #  Concatenate the results\n",
    "        # ======================================================================\n",
    "        self.confidences = torch.cat(self.confidences, 1)\n",
    "        self.locations = torch.cat(self.locations, 1)\n",
    "            \n",
    "        # ======================================================================\n",
    "        # Return the results\n",
    "        # ======================================================================\n",
    "        if self.is_inference:\n",
    "            self.confidences = F.softmax(self.confidences, dim=2)\n",
    "            self.boxes = box_utils.convert_locations_to_boxes(\n",
    "                self.locations, self.priors, self.config.center_variance, self.config.size_variance\n",
    "            )\n",
    "            self.boxes = box_utils.center_form_to_corner_form(self.boxes)\n",
    "            return self.confidences, self.boxes, z\n",
    "        else:\n",
    "            return self.confidences, self.locations, z\n",
    "\n",
    "    ####################################################################################################\n",
    "\n",
    "    # computer classification and regression layers\n",
    "    def compute_header(self, i, x):\n",
    "        #  Classification for confidence (6 sets of 21 numbers for each grid)\n",
    "        confidence = self.classification_headers[i](x)\n",
    "        confidence = confidence.permute(0, 2, 3, 1).contiguous()\n",
    "        confidence = confidence.view(confidence.size(0), -1, self.num_classes)\n",
    "        \n",
    "        #  Regression for location (6 sets of 4 numbers for each grid)\n",
    "        location = self.regression_headers[i](x)\n",
    "        location = location.permute(0, 2, 3, 1).contiguous()\n",
    "        location = location.view(location.size(0), -1, 4)\n",
    "\n",
    "        return confidence, location\n",
    "\n",
    "    def init_base_net(self, model):\n",
    "        self.base_net.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage), strict=True)\n",
    "        self.source_layer_add_ons.apply(_xavier_init_)\n",
    "        self.extras.apply(_xavier_init_)\n",
    "        self.classification_headers.apply(_xavier_init_)\n",
    "        self.regression_headers.apply(_xavier_init_)\n",
    "        if self.encoder_headers: self.encoder_headers.apply(_xavier_init_)\n",
    "\n",
    "    def init_from_pretrained_ssd(self, model_path, log=print):\n",
    "        state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "        state_dict = state_dict['model_state_dict']\n",
    "        # state_dict = {k: v for k, v in state_dict.items() if not (k.startswith(\"classification_headers\") or k.startswith(\"regression_headers\"))}\n",
    "        state_dict = {k: v for k, v in state_dict.items() if not (k.startswith(\"discriminator_headers\") or k.startswith(\"encoder_headers\"))}\n",
    "        model_dict = self.state_dict()\n",
    "        model_dict.update(state_dict)\n",
    "        self.load_state_dict(model_dict)\n",
    "        log(f\"Loaded pretrained SSD.\")\n",
    "            \n",
    "    def init_encoder(self, model):\n",
    "        if self.encoder_headers:\n",
    "            state_dict = torch.load(model, map_location=lambda storage, loc: storage)\n",
    "            state_dict = state_dict['model_state_dict']\n",
    "            state_dict = {k: v for k, v in state_dict.items() if (k.startswith(\"encoder_headers\"))}\n",
    "            model_dict = self.state_dict()\n",
    "            model_dict.update(state_dict)\n",
    "            self.load_state_dict(model_dict)\n",
    "            train_log.info(f\"Loaded pretrained encoder from {model}.\")\n",
    "\n",
    "    def init(self):\n",
    "        self.base_net.apply(_xavier_init_)\n",
    "        self.source_layer_add_ons.apply(_xavier_init_)\n",
    "        self.extras.apply(_xavier_init_)\n",
    "        self.classification_headers.apply(_xavier_init_)\n",
    "        self.regression_headers.apply(_xavier_init_)\n",
    "        if self.encoder_headers: self.encoder_headers.apply(_xavier_init_)\n",
    "\n",
    "    def load(self, model):\n",
    "        self.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    def save(self, privacy_flag, public_flag, alpha, max_grad_norm, epoch, optimizers, schedulers, val_loss, val_d_ent, val_d_loss, \n",
    "             sensitive_classes, model_path, discriminator_loc=None, discriminator=None, public=None, val_p_loss=None, public_classes=None,\n",
    "             arl_setting = None):\n",
    "        dic = {'privacy_flag': privacy_flag, \n",
    "               'public_flag': public_flag,\n",
    "               'epoch': epoch,\n",
    "               'model_state_dict': self.state_dict(),\n",
    "               'max_grad_norm': max_grad_norm, \n",
    "               'optimizer_state_dict': optimizers[0].optimizer.state_dict(),\n",
    "               'scheduler_stat_dict': schedulers[0].state_dict(),\n",
    "               'loss': val_loss,\n",
    "              }\n",
    "        \n",
    "        if discriminator:\n",
    "            dic['alpha'] = alpha\n",
    "            dic['arl_setting'] = arl_setting\n",
    "            dic['sensitive_classes'] = sensitive_classes\n",
    "            dic['discriminator_loc'] = discriminator_loc\n",
    "            dic['entropy'] = val_d_ent\n",
    "            dic['discrimiantor_loss'] = val_d_loss\n",
    "            dic['discriminator_optimizer_state_dict'] = optimizers[1].optimizer.state_dict()\n",
    "            dic['discriminator_scheduler_state_dict'] = schedulers[1].state_dict()\n",
    "            dic['discriminator_state_dict'] = discriminator.state_dict()\n",
    "            \n",
    "        if public_flag:\n",
    "            dic['public_state_dict'] = public.state_dict()\n",
    "            dic['public_optimizer_state_dict'] = optimizers[2].optimizer.state_dict()\n",
    "            dic['public_scheduler_state_dict'] = schedulers[2].state_dict()\n",
    "            dic['public_loss'] = val_p_loss\n",
    "            dic['public_classes'] = public_classes\n",
    "            \n",
    "        torch.save(dic, model_path)\n",
    "        \n",
    "    def save_attack(self, privacy_flag, alpha, max_grad_norm, epoch, optimizers, schedulers, ssd_loss, attacker_loss, \n",
    "                    sensitive_classes, entropy, model_path, discriminator_loc=None, discriminator=None,\n",
    "                    attacker_loc=None, attacker=None, name=None):\n",
    "        \n",
    "        dic = {'privacy_flag': True, \n",
    "               'epoch': epoch,\n",
    "               'model_state_dict': self.state_dict(),\n",
    "               'max_grad_norm': max_grad_norm, \n",
    "               'loss': ssd_loss,\n",
    "               'public_flag': False\n",
    "              }\n",
    "\n",
    "        \n",
    "        dic['attacked_model'] = name\n",
    "        dic['alpha'] = alpha\n",
    "        dic['sensitive_classes'] = sensitive_classes\n",
    "        dic['attacker_loss'] = attacker_loss\n",
    "        dic['attacker_loc'] = attacker_loc\n",
    "        dic['attacker_optimizer_state_dict'] = optimizers[1].optimizer.state_dict()\n",
    "        dic['attacker_scheduler_state_dict'] = schedulers[1].optimizer.state_dict()\n",
    "        dic['attacker_state_dict'] = attacker.state_dict()\n",
    "        dic['entropy'] = entropy\n",
    "            \n",
    "        torch.save(dic, model_path)\n",
    "        \n",
    "class MatchPrior(object):\n",
    "    \n",
    "    def __init__(self, center_form_priors, center_variance, size_variance, iou_threshold):\n",
    "        self.center_form_priors = center_form_priors\n",
    "        self.corner_form_priors = box_utils.center_form_to_corner_form(center_form_priors)\n",
    "        self.center_variance = center_variance\n",
    "        self.size_variance = size_variance\n",
    "        self.iou_threshold = iou_threshold\n",
    "\n",
    "    def __call__(self, gt_boxes, gt_labels):\n",
    "        if type(gt_boxes) is np.ndarray:\n",
    "            gt_boxes = torch.from_numpy(gt_boxes)\n",
    "        if type(gt_labels) is np.ndarray:\n",
    "            gt_labels = torch.from_numpy(gt_labels)\n",
    "        boxes, labels = box_utils.assign_priors(gt_boxes, gt_labels,\n",
    "                                                self.corner_form_priors, self.iou_threshold)\n",
    "        boxes = box_utils.corner_form_to_center_form(boxes)\n",
    "        locations = box_utils.convert_boxes_to_locations(boxes, self.center_form_priors, self.center_variance, self.size_variance)\n",
    "        return locations, labels\n",
    "\n",
    "def _xavier_init_(m: nn.Module):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "def freeze_net_layers(net):\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE7xozNhqUeS"
   },
   "source": [
    "BatchNorm might still cause the gradient updates:https://discuss.pytorch.org/t/why-is-it-when-i-call-require-grad-false-on-all-my-params-my-weights-in-the-network-would-still-update/22126/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmhUPOzcP6a2"
   },
   "source": [
    "vgg\n",
    "borrowed from https://github.com/amdegroot/ssd.pytorch/blob/master/ssd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKZA4QJdrlJS"
   },
   "source": [
    "## mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yUwQE8b5hG9b"
   },
   "outputs": [],
   "source": [
    "# Modified from https://github.com/tonylins/pytorch-mobilenet-v2/blob/master/MobileNetV2.py.\n",
    "# In this version, Relu6 is replaced with Relu to make it ONNX compatible.\n",
    "# BatchNorm Layer is optional to make it easy do batch norm confusion.\n",
    "\n",
    "\n",
    "def conv_bn(inp, oup, stride, use_batch_norm=True, onnx_compatible=False):\n",
    "    ReLU = nn.ReLU if onnx_compatible else nn.ReLU6\n",
    "\n",
    "    if use_batch_norm:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "            ReLU(inplace=True)\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "            ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup, use_batch_norm=True, onnx_compatible=False):\n",
    "    ReLU = nn.ReLU if onnx_compatible else nn.ReLU6\n",
    "    if use_batch_norm:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "            ReLU(inplace=True)\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "            ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio, use_batch_norm=True, onnx_compatible=False):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        ReLU = nn.ReLU if onnx_compatible else nn.ReLU6\n",
    "\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            if use_batch_norm:\n",
    "                self.conv = nn.Sequential(\n",
    "                    # dw\n",
    "                    nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                    nn.BatchNorm2d(hidden_dim),\n",
    "                    ReLU(inplace=True),\n",
    "                    # pw-linear\n",
    "                    nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                    nn.BatchNorm2d(oup),\n",
    "                )\n",
    "            else:\n",
    "                self.conv = nn.Sequential(\n",
    "                    # dw\n",
    "                    nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                    ReLU(inplace=True),\n",
    "                    # pw-linear\n",
    "                    nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                )\n",
    "        else:\n",
    "            if use_batch_norm:\n",
    "                self.conv = nn.Sequential(\n",
    "                    # pw (pointwise)\n",
    "                    nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                    nn.BatchNorm2d(hidden_dim),\n",
    "                    ReLU(inplace=True),\n",
    "                    # dw (depthwise)\n",
    "                    nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                    nn.BatchNorm2d(hidden_dim),\n",
    "                    ReLU(inplace=True),\n",
    "                    # pw-linear\n",
    "                    nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                    nn.BatchNorm2d(oup),\n",
    "                )\n",
    "            else:\n",
    "                self.conv = nn.Sequential(\n",
    "                    # pw (pointwise)\n",
    "                    nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                    ReLU(inplace=True),\n",
    "                    # dw (depthwise)\n",
    "                    nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                    ReLU(inplace=True),\n",
    "                    # pw-linear\n",
    "                    nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, n_class=1000, input_size=224, width_mult=1., dropout_ratio=0.2,\n",
    "                 use_batch_norm=True, onnx_compatible=False):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        input_channel = int(input_channel * width_mult)\n",
    "        self.last_channel = int(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2, onnx_compatible=onnx_compatible)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, s,\n",
    "                                               expand_ratio=t, use_batch_norm=use_batch_norm,\n",
    "                                               onnx_compatible=onnx_compatible))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1,\n",
    "                                               expand_ratio=t, use_batch_norm=use_batch_norm,\n",
    "                                               onnx_compatible=onnx_compatible))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel,\n",
    "                                         use_batch_norm=use_batch_norm, onnx_compatible=onnx_compatible))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(self.last_channel, n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def SeperableConv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, onnx_compatible=False):\n",
    "    \"\"\"Replace Conv2d with a depthwise Conv2d and Pointwise Conv2d.\n",
    "    \"\"\"\n",
    "    ReLU = nn.ReLU if onnx_compatible else nn.ReLU6\n",
    "    return Sequential(\n",
    "        Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size,\n",
    "               groups=in_channels, stride=stride, padding=padding),\n",
    "        BatchNorm2d(in_channels),\n",
    "        ReLU(),\n",
    "        Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGMKDLC4_A4"
   },
   "source": [
    "## ssd_create\n",
    "\n",
    "* default: 6 boxes\n",
    "\n",
    "* MobileNetV2.features = [conv_bn(3, input_channel, 2, onnx_compatible=onnx_compatible)]\n",
    "\n",
    "* extras --> used for the last layer feature map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tvHRcoY6nwEC"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, Sequential, ModuleList, BatchNorm2d\n",
    "\n",
    "class create_mobilenetv2_ssd_lite:\n",
    "\n",
    "    def __init__(self, num_classes, width_mult=1.0, use_batch_norm=True, onnx_compatible=False, is_test=False):\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.is_test = is_test\n",
    "\n",
    "        # networks\n",
    "        self.base_net = MobileNetV2(width_mult=width_mult, use_batch_norm=use_batch_norm, onnx_compatible=onnx_compatible).features\n",
    "        self.source_layer_indexes = [GraphPath(14, 'conv', 3),19,]\n",
    "        self.extras = ModuleList([\n",
    "            InvertedResidual(1280, 512, stride=2, expand_ratio=0.2),\n",
    "            InvertedResidual(512, 256, stride=2, expand_ratio=0.25),\n",
    "            InvertedResidual(256, 256, stride=2, expand_ratio=0.5),\n",
    "            InvertedResidual(256, 64, stride=2, expand_ratio=0.25)\n",
    "            ])\n",
    "        \n",
    "        self.regression_headers = ModuleList([\n",
    "            SeperableConv2d(in_channels=round(576 * width_mult), out_channels=6 * 4, kernel_size=3, padding=1, onnx_compatible=False),\n",
    "            SeperableConv2d(in_channels=1280, out_channels=6 * 4, kernel_size=3, padding=1, onnx_compatible=False),\n",
    "            SeperableConv2d(in_channels=512, out_channels=6 * 4, kernel_size=3, padding=1, onnx_compatible=False),\n",
    "            SeperableConv2d(in_channels=256, out_channels=6 * 4, kernel_size=3, padding=1, onnx_compatible=False),\n",
    "            SeperableConv2d(in_channels=256, out_channels=6 * 4, kernel_size=3, padding=1, onnx_compatible=False),\n",
    "            Conv2d(in_channels=64, out_channels=6 * 4, kernel_size=1),\n",
    "            ])\n",
    "\n",
    "        self.classification_headers = ModuleList([\n",
    "            SeperableConv2d(in_channels=round(576 * width_mult), out_channels=6 * num_classes, kernel_size=3, padding=1),\n",
    "            SeperableConv2d(in_channels=1280, out_channels=6 * num_classes, kernel_size=3, padding=1),\n",
    "            SeperableConv2d(in_channels=512, out_channels=6 * num_classes, kernel_size=3, padding=1),\n",
    "            SeperableConv2d(in_channels=256, out_channels=6 * num_classes, kernel_size=3, padding=1),\n",
    "            SeperableConv2d(in_channels=256, out_channels=6 * num_classes, kernel_size=3, padding=1),\n",
    "            Conv2d(in_channels=64, out_channels=6 * num_classes, kernel_size=1),\n",
    "            ])\n",
    "\n",
    "        self.encoder_headers = ModuleList()\n",
    "        \n",
    "    def create_SSD(self):\n",
    "        \n",
    "        return SSD(self.num_classes,\n",
    "                   self.base_net, \n",
    "                   self.source_layer_indexes, \n",
    "                   self.extras, \n",
    "                   self.classification_headers, \n",
    "                   self.regression_headers, \n",
    "                   self.encoder_headers,\n",
    "                   is_test= self.is_test, \n",
    "                   config = mobilenetv1_ssd_config\n",
    "                   )\n",
    "\n",
    "    def create_SSD1(self):\n",
    "        \n",
    "        return 0\n",
    "\n",
    "def create_mobilenetv2_ssd_lite_predictor(net, candidate_size=200, nms_method=None, sigma=0.5, device=torch.device('cpu'), config = mobilenetv1_ssd_config):\n",
    "    predictor = Predictor(net, config.image_size, config.image_mean,\n",
    "                          config.image_std,\n",
    "                          nms_method=nms_method,\n",
    "                          iou_threshold=config.iou_threshold,\n",
    "                          candidate_size=candidate_size,\n",
    "                          sigma=sigma,\n",
    "                          device=device)\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4qrdFeqiDDW"
   },
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Discriminator():\n",
    "    def __init__(self):\n",
    "        self.discsriminator_headers = ModuleList()\n",
    "        self.discriminator_A_settings = {\n",
    "                                         0:[32, 22500],   2:[96, 1000],\n",
    "                                         7:[192, 250],  11:[384, 90],  14:[576, 90],\n",
    "                                         18:[1280, 40], 19:[512, 10],   20:[256, 10],\n",
    "                                         21:[256, 10],    22:[64, 40]\n",
    "                                         }\n",
    "        \n",
    "    def build(self, d_loc):\n",
    "        input_size = self.discriminator_A_settings[d_loc]\n",
    "        return Discriminator(cnn_input=input_size[0], linear_input=input_size[1])\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, cnn_input, linear_input, d_type=\"A\"):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net_headers = self.A(cnn_input, linear_input)\n",
    "        self.net_headers.apply(_xavier_init_)\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            self.net_headers = self.net_headers.cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.net_headers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "#     def load(self, path, is_attacker=False):\n",
    "#         state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "#         state_dict = state_dict['discriminator_state_dict'] if not is_attacker else state_dict['attacker_state_dict']\n",
    "#         # state_dict = {k: v for k, v in state_dict.items()} #(k.startswith(\"encoder_headers\")\n",
    "#         #print(len(state_dict.keys()))\n",
    "#         model_dict = self.state_dict()\n",
    "#         model_dict.update(state_dict)\n",
    "#         self.load_state_dict(model_dict)\n",
    "        \n",
    "    def load(self, path, module=\"discriminator\"):\n",
    "        state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        if module == \"discriminator\":\n",
    "            state_dict = state_dict['discriminator_state_dict'] \n",
    "        elif module == \"attacker\":\n",
    "            state_dict = state_dict['attacker_state_dict']\n",
    "        elif module == \"public\": \n",
    "            state_dict = state_dict['public_state_dict']\n",
    "        else:\n",
    "            raise Exception(f\"Only discriminator, attacker, or public.\")\n",
    "        # state_dict = {k: v for k, v in state_dict.items()} #(k.startswith(\"encoder_headers\")\n",
    "        #print(len(state_dict.keys()))\n",
    "        model_dict = self.state_dict()\n",
    "        model_dict.update(state_dict)\n",
    "        self.load_state_dict(model_dict)\n",
    "    \n",
    "    \n",
    "    def load_discriminator(self, model):\n",
    "        if self.discriminator_headers:\n",
    "            self.discriminator_headers.apply(_xavier_init_)\n",
    "            if self.feature_map == -1 or self.feature_map == 24:\n",
    "                self.discriminator_headers[0].load_state_dict(torch.load(model, map_location=lambda storage, loc: storage), strict=True)\n",
    "                print(f\"Loaded {discriminator_type} in discriminator.\") # load image_net 71.8\n",
    "        else:\n",
    "            print(\"No discriminator to load.\")\n",
    "            \n",
    "    def init_attacker(self, net):\n",
    "        if self.discriminator_headers:\n",
    "            state_dict = torch.load(model, map_location=lambda storage, loc: storage)\n",
    "            state_dict = state_dict['model_state_dict']\n",
    "            state_dict = {k: v for k, v in state_dict.items() if (k.startswith(\"discriminator_headers\"))}\n",
    "            model_dict = self.state_dict()\n",
    "            model_dict.update(state_dict)\n",
    "            self.load_state_dict(model_dict)\n",
    "            print(f\"Loaded attacker from {model[20:]}.\") # load image_net 71.8\n",
    "        else:\n",
    "            print(\"No attacker to load.\")\n",
    "        \n",
    "    def A(self, cnn_input=1280, linear_input=10, width_mult=1.0, use_batch_norm=True, onnx_compatible=False):\n",
    "        return ModuleList([\n",
    "                    InvertedResidual(cnn_input, 512, stride=2, expand_ratio=0.2),\n",
    "                    InvertedResidual(512, 256, stride=2, expand_ratio=0.25),\n",
    "#                     InvertedResidual(256, 256, stride=2, expand_ratio=0.5),\n",
    "                    InvertedResidual(256, 64, stride=2, expand_ratio=0.25),\n",
    "                    SeperableConv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1),\n",
    "                    SeperableConv2d(in_channels=32, out_channels=10, kernel_size=3, padding=1),\n",
    "                    Flatten(),\n",
    "                    nn.Linear(linear_input, 2)\n",
    "                ])\n",
    "    \n",
    "    def BE(self, encoder_expand_ratio=12):           \n",
    "        return ModuleList([\n",
    "                    SeperableConv2d(in_channels=3*encoder_expand_ratio, out_channels=10, kernel_size=5, padding=0, stride=3),\n",
    "                    nn.Linear(98010,2)\n",
    "                ])\n",
    "\n",
    "    def B(self):\n",
    "\n",
    "        #             discriminator_headers = ModuleList([\n",
    "        #                 SeperableConv2d(in_channels=3*encoder_expand_ratio, out_channels=10, kernel_size=5, padding=0, stride=3),\n",
    "        #                 nn.Linear(98010,2)\n",
    "        #             ])\n",
    "\n",
    "        #             discriminator_headers = ModuleList([\n",
    "        #                 InvertedResidual(3, 8, stride=2, expand_ratio=6),\n",
    "        #                 InvertedResidual(8, 16, stride=2, expand_ratio=6),\n",
    "        #                 InvertedResidual(16, 32, stride=2, expand_ratio=4),\n",
    "        #                 InvertedResidual(32, 64, stride=2, expand_ratio=3),\n",
    "        #                 InvertedResidual(64, 64, stride=2, expand_ratio=3),\n",
    "        #                 SeperableConv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0, stride=2),\n",
    "        #                 BatchNorm2d(128),\n",
    "        #                 nn.ReLU(inplace=True),\n",
    "        #                 SeperableConv2d(in_channels=128, out_channels=256, kernel_size=3, padding=0, stride=2),\n",
    "        #                 nn.Linear(256,2)\n",
    "        #             ])\n",
    "\n",
    "        return ModuleList([\n",
    "                    SeperableConv2d(in_channels=3, out_channels=10, kernel_size=5, padding=0, stride=3),\n",
    "                    nn.Linear(98010,2)\n",
    "                    ])\n",
    "\n",
    "    def vgg(self):\n",
    "        vgg_base_net = ModuleList(vgg(vgg_config))\n",
    "        vgg_base_net = nn.Sequential(*vgg_base_net)\n",
    "        return ModuleList([\n",
    "                    vgg_base_net,\n",
    "                    BatchNorm2d(1024),\n",
    "                    SeperableConv2d(in_channels=1024, out_channels=512, kernel_size=5, padding=0, stride=3),\n",
    "                    nn.Linear(12800,2)\n",
    "                    ])\n",
    "\n",
    "    def ssd(self, width_mult=1.0, use_batch_norm=True, onnx_compatible=False):\n",
    "        base_net_dis = MobileNetV2(width_mult=width_mult, use_batch_norm=use_batch_norm, onnx_compatible=onnx_compatible).features\n",
    "        return ModuleList([\n",
    "                            base_net_dis,\n",
    "                            InvertedResidual(1280, 512, stride=2, expand_ratio=0.2),\n",
    "                            InvertedResidual(512, 256, stride=2, expand_ratio=0.25),\n",
    "                            InvertedResidual(256, 256, stride=2, expand_ratio=0.5),\n",
    "                            InvertedResidual(256, 64, stride=2, expand_ratio=0.25),\n",
    "                            SeperableConv2d(in_channels=64, out_channels=10, kernel_size=3, padding=1),\n",
    "                            nn.Linear(10, 2)\n",
    "                            ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFqeEWkK_y17"
   },
   "source": [
    "# Losses\n",
    "\n",
    "Classification: hard negative mining --> if an image has y classes, choose 3y backgrounds based on the loss magnitude\n",
    "\n",
    "Regression: set the background boxes to zero. (because we don't need to update the box size of the background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiboxLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iMFKTy0C_y_W"
   },
   "outputs": [],
   "source": [
    "from vision.utils import box_utils\n",
    "\n",
    "class MultiboxLoss(nn.Module):\n",
    "    def __init__(self, priors, iou_threshold, neg_pos_ratio,\n",
    "                 center_variance, size_variance, device):\n",
    "        \"\"\"Implement SSD Multibox Loss.\n",
    "        Basically, Multibox loss combines classification loss\n",
    "         and Smooth L1 regression loss.\n",
    "        \"\"\"\n",
    "        super(MultiboxLoss, self).__init__()\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.neg_pos_ratio = neg_pos_ratio\n",
    "        self.center_variance = center_variance\n",
    "        self.size_variance = size_variance\n",
    "        # self.priors = priors\n",
    "        # self.priors.to(device)\n",
    "\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.regression_loss=torch.FloatTensor(0)\n",
    "        self.classification_loss=torch.FloatTensor(0)\n",
    "        self.grad_disc_out = torch.zeros(0)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            self.regression_loss=self.regression_loss.cuda()\n",
    "            self.classification_loss=self.classification_loss.cuda()\n",
    "            self.grad_disc_out=self.grad_disc_out.cuda()\n",
    "\n",
    "    def forward(self, confidence, predicted_locations, labels, gt_locations, \n",
    "                dis_prediction = 0, dis_gt_labels = 0, original_flag = True, eval = False, freeze_ssd = False):\n",
    "\n",
    "        \"\"\"Compute classification loss and smooth l1 loss.\n",
    "        Args:\n",
    "            confidence (batch_size, num_priors, num_classes): class predictions.\n",
    "            locations (batch_size, num_priors, 4): predicted locations.\n",
    "            labels (batch_size, num_priors): real labels of all the priors.\n",
    "            boxes (batch_size, num_priors, 4): real boxes corresponding all the priors.\n",
    "        \"\"\"\n",
    "\n",
    "        num_classes = confidence.size(2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # derived from cross_entropy=sum(log(p))\n",
    "            loss = -F.log_softmax(confidence, dim=2)[:, :, 0]\n",
    "            \"\"\" Why does it only choose the first one? \"\"\"\n",
    "            mask = hard_negative_mining(loss, labels, self.neg_pos_ratio)\n",
    "        \n",
    "        #  Total Classification Loss\n",
    "        confidence = confidence[mask, :]\n",
    "        if not original_flag: confidence = Variable(confidence.data, requires_grad=(not eval and not freeze_ssd)).contiguous()\n",
    "        self.classification_loss = F.cross_entropy(confidence.reshape(-1, num_classes), labels[mask], reduction='sum')\n",
    "\n",
    "        #  Total Regression Loss \n",
    "        pos_mask = labels > 0\n",
    "        predicted_locations = predicted_locations[pos_mask, :].reshape(-1, 4)\n",
    "        if not original_flag: predicted_locations = Variable(predicted_locations.data, requires_grad=(not eval and not freeze_ssd)).contiguous()\n",
    "        gt_locations = gt_locations[pos_mask, :].reshape(-1, 4)\n",
    "        smooth_l1_loss = F.smooth_l1_loss(predicted_locations, gt_locations, reduction='sum')\n",
    "\n",
    "        # Average Losses\n",
    "        num_pos = gt_locations.size(0)\n",
    "        \n",
    "        \n",
    "        if not original_flag:\n",
    "            self.classification_loss = torch.true_divide(self.classification_loss, num_pos)\n",
    "            self.regression_loss = torch.true_divide(smooth_l1_loss, num_pos)\n",
    "            return self.classification_loss, self.regression_loss\n",
    "        \n",
    "        else:\n",
    "            return self.classification_loss/num_pos, smooth_l1_loss/num_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "P_Yz4nd4_zCf"
   },
   "outputs": [],
   "source": [
    "def hard_negative_mining(loss, labels, neg_pos_ratio):\n",
    "    \"\"\"\n",
    "    It used to suppress the presence of a large number of negative prediction.\n",
    "    It works on image level not batch level.\n",
    "    For any example/image, it keeps all the positive predictions and\n",
    "     cut the number of negative predictions to make sure the ratio\n",
    "     between the negative examples and positive examples is no more\n",
    "     the given ratio for an image.\n",
    "    Args:\n",
    "        loss (N, num_priors): the loss for each example.\n",
    "        labels (N, num_priors): the labels.\n",
    "        neg_pos_ratio:  the ratio between the negative examples and positive examples.\n",
    "    \"\"\"\n",
    "    pos_mask = labels > 0\n",
    "    num_pos = pos_mask.long().sum(dim=1, keepdim=True) # the number of positive label in an image\n",
    "    num_neg = num_pos * neg_pos_ratio # the total number of labels to use in an image\n",
    "\n",
    "    loss[pos_mask] = -math.inf\n",
    "    _, indexes = loss.sort(dim=1, descending=True)\n",
    "    _, orders = indexes.sort(dim=1)\n",
    "    neg_mask = orders < num_neg\n",
    "    return pos_mask | neg_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from  torch.nn.modules.loss import _Loss\n",
    "\n",
    "class EntropyLoss(_Loss):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(EntropyLoss, self).__init__(size_average, reduce, reduction)\n",
    "\n",
    "    # input is probability distribution of output classes\n",
    "    def forward(self, input):\n",
    "        if (input < 0).any() or (input > 1).any():\n",
    "            raise Exception('Entropy Loss takes probabilities 0<=input<=1')\n",
    "\n",
    "        input = input + 1e-16  # for numerical stability while taking log\n",
    "        H = torch.mean(torch.sum(input * torch.log(input), dim=1))\n",
    "        \n",
    "        return H\n",
    "    \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq8vSYTlot_v"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuELTaw8U7cx"
   },
   "source": [
    "param = list(fc1.parameters()) + list(fc2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_z5vtFtuoB-k"
   },
   "outputs": [],
   "source": [
    "class Optim(object):\n",
    "\n",
    "    def _makeOptimizer(self):\n",
    "        if self.method == 'sgd':\n",
    "            self.optimizer = optim.SGD(self.params, lr=self.lr, momentum=self.sgd_momentum, weight_decay=self.sgd_weight_decay)\n",
    "        elif self.method == 'adagrad':\n",
    "            self.optimizer = optim.Adagrad(self.params, lr=self.lr)\n",
    "        elif self.method == 'adadelta':\n",
    "            self.optimizer = optim.Adadelta(self.params, lr=self.lr)\n",
    "        elif self.method == 'adam':\n",
    "            self.optimizer = optim.Adam(self.params, lr=self.lr, betas=(self.adam_momentum, 0.999))\n",
    "        else:\n",
    "            raise RuntimeError(\"Invalid optim method: \" + self.method)\n",
    "\n",
    "    def __init__(self, params, method, enc_params = [0],  max_grad_norm = 5, lr = 0.001, lr_decay=1,\n",
    "                 start_decay_at= 60, adam_momentum=0.9, sgd_momentum = 0.9, sgd_weight_decay = 5e-4, privacy_flag=False):\n",
    "        \n",
    "        self.params = params  # careful: params may be a generator\n",
    "        self.encoder_params = list(enc_params)\n",
    "        self.last_ppl = None\n",
    "        self.lr = lr\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.method = method\n",
    "        self.lr_decay = lr_decay\n",
    "        self.start_decay_at = start_decay_at\n",
    "        self.start_decay = False\n",
    "        self.adam_momentum = adam_momentum\n",
    "        self.sgd_momentum = sgd_momentum\n",
    "        self.sgd_weight_decay = sgd_weight_decay\n",
    "        self._makeOptimizer()\n",
    "\n",
    "    def step_all(self):\n",
    "        #  Calculate encoder gradient norm\n",
    "        \n",
    "        enc_grad_norm = 0.0\n",
    "        for param in self.encoder_params:\n",
    "            enc_grad_norm += math.pow(param.grad.data.norm(), 2) if param.grad != None else 0.0\n",
    "        enc_grad_norm = math.sqrt(enc_grad_norm)\n",
    "\n",
    "        #  Calculate all gradient norm\n",
    "        grad_norm = 0.0\n",
    "        for param in self.params:\n",
    "            for p in param['params']:\n",
    "                grad_norm += math.pow(p.grad.data.norm(), 2) \n",
    "        grad_norm = math.sqrt(grad_norm)\n",
    "\n",
    "        #  Shrink the graident if the gradients are too large\n",
    "        shrinkage = self.max_grad_norm / grad_norm\n",
    "        for param in self.params:\n",
    "            for p in param['params']:\n",
    "                if shrinkage < 1:\n",
    "                    p.grad.data.mul_(shrinkage)\n",
    "\n",
    "        #  Start updating\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return enc_grad_norm, grad_norm, shrinkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZNjrMqrb97b"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFsgA3uTEg_D"
   },
   "source": [
    "## maxent_network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUvKnQLmwFkb"
   },
   "source": [
    "https://www.zhihu.com/question/61044004 register_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TfNj1mdwjuP6"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\n",
    "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.0\n",
    "        self.avg = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0.0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fAGA0oT6DAUU"
   },
   "outputs": [],
   "source": [
    "class Maxtrain_Network:\n",
    "    def __init__(self, nets, optimizers, train_loader, test_loader, alpha = None, sensitive_class = None, public_classes = None, log=print):\n",
    "        \n",
    "        self.log=log\n",
    "        self.net = nets[0]                \n",
    "        self.discriminator = nets[1]\n",
    "        self.public = nets[2]\n",
    "        \n",
    "        self.optimizer = optimizers[0]\n",
    "        self.discriminator_optimizer = optimizers[1]\n",
    "        self.public_optimizer = optimizers[2]\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.sensitive_classes = sensitive_class\n",
    "        self.public_classes = public_classes\n",
    "        \n",
    "        self.entropy_loss = EntropyLoss()\n",
    "        self.softmaxlayer = nn.Softmax(dim=1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.nll_loss = nn.NLLLoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.images = torch.zeros(0, 0, 0)\n",
    "        self.boxes = torch.zeros(0, 0, 0)\n",
    "        self.labels = torch.zeros(0, dtype=torch.long)\n",
    "        self.sensitive_labels = torch.zeros(0, dtype=torch.long)\n",
    "        self.public_labels = torch.zeros(0, dtype=torch.long)\n",
    "        self.grad_norm = torch.tensor(1.0)\n",
    "\n",
    "\n",
    "        if self.use_cuda:\n",
    "            self.images=self.images.cuda()\n",
    "            self.boxes=self.boxes.cuda()\n",
    "            self.labels=self.labels.cuda()\n",
    "            self.grad_norm=self.grad_norm.cuda()\n",
    "\n",
    "            if self.discriminator:\n",
    "                self.sensitive_labels = self.sensitive_labels.cuda()\n",
    "                self.alpha = self.alpha.to(DEVICE) \n",
    "            \n",
    "            if self.public:\n",
    "                self.public_labels = self.public_labels.cuda()\n",
    "        \n",
    "        self.meters_reset()\n",
    "\n",
    "    def meters_reset(self):\n",
    "        self.running_loss = 0.0\n",
    "        self.running_regression_loss = 0.0\n",
    "        self.running_classification_loss = 0.0\n",
    "        self.running_regression_loss_dis = 0.0\n",
    "        self.running_discriminator_loss = 0.0\n",
    "        self.report_grad_norm = 0.0\n",
    "        self.running_ssd_loss = 0.0\n",
    "        self.running_discriminator_entropy = 0.0\n",
    "        self.running_public_loss = 0.0\n",
    "\n",
    "    def online_find_labels(self, labels, target_classes=[15]):\n",
    "        label_temp = torch.zeros(len(labels), dtype=torch.long)\n",
    "        for j in range(len(label_temp)):\n",
    "            label_temp[j] = (1 if any(items in labels[j].unique() for items in target_classes) else 0)\n",
    "        return label_temp\n",
    "\n",
    "    def compute_gradnorm(self):\n",
    "        grad_sum = 0\n",
    "        for param in list(filter(lambda p: p.grad is not None, self.net.parameters())):\n",
    "            grad_sum += math.pow(param.grad.data.norm(), 2) \n",
    "        return math.sqrt(grad_sum)\n",
    "    \n",
    "    def call_param(self, net_header, name, print_out=False):\n",
    "        all_param = [param.detach().clone() for param in net_header.parameters()] \n",
    "        if print_out: print(f\"{name}:{all_param[0][0][0]}\")\n",
    "        return all_param\n",
    "\n",
    "    def assert_param(self, p1, p2):\n",
    "        assert len(p1) == len(p2)\n",
    "        for i in range(len(p1)): assert torch.sum(p1[i] == p2[i]) == p1[i].numel()\n",
    "\n",
    "    def grad_summation(self, grads):\n",
    "        grad_sum = 0 \n",
    "        for grad in grads:\n",
    "            if grad != None: grad_sum += torch.sum(grad)\n",
    "        return grad_sum\n",
    "\n",
    "    def train_net(self, net, net_optim, net_input, net_labels):\n",
    "        \n",
    "        net_input = net(net_input)\n",
    "        net_prob = self.softmaxlayer(net_input)\n",
    "        net_loss = self.nll_loss(torch.log(net_prob+1e-16), net_labels)\n",
    "\n",
    "        # Backprop\n",
    "        net_optim.optimizer.zero_grad()\n",
    "        net_loss.backward()\n",
    "        _, grad_norm, _ = net_optim.step_all()\n",
    "\n",
    "#         d_prec1 = accuracy(d_prob.data, self.sensitive_label.data)\n",
    "#         d_prec5 = accuracy(d_prob.data, self.sensitive_label.data, topk=(int(np.min([5, sensitive_classes])),))\n",
    "\n",
    "        return net_loss, grad_norm\n",
    "\n",
    "    \n",
    "\n",
    "    def arl_train(self, criterion, d_loc=None, privacy_flag=True, public_flag = False, arl_setting='maxent-arl', debug_steps=100, epoch=-1, verbose=False):\n",
    "        ''' ===================================================================================\n",
    "        Main Algorithm:\n",
    "            1. Train encoder and decoder with discriminator loss\n",
    "            2. Train discriminator\n",
    "        ========================================================================================'''\n",
    "        self.net.train(True)\n",
    "        if privacy_flag: self.discriminator.train(True)\n",
    "        if public_flag: self.public.train(True)\n",
    "        self.meters_reset()\n",
    "\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "\n",
    "            # Prepare data\n",
    "            if i%10 == 0 and i: print(end='.')\n",
    "            self.images.resize_(data[0].size()).copy_(data[0])\n",
    "            self.boxes.resize_(data[1].size()).copy_(data[1])\n",
    "            self.labels.resize_(data[2].size()).copy_(data[2])\n",
    "\n",
    "            # 1. Train Encoder + Predictor =============\n",
    "            confidence, locations, z = self.net(self.images, d_loc)\n",
    "            class_loss, reg_loss = criterion(confidence, locations, self.labels, self.boxes)\n",
    "            ssd_loss = class_loss + reg_loss\n",
    "                    \n",
    "            # Other public task other than object detection\n",
    "            if public_flag:\n",
    "                public_labels = data[4] if len(data) == 5 else self.online_find_labels(self.labels, self.public_classes)\n",
    "                self.public_labels.resize_(public_labels.size()).copy_(public_labels)     \n",
    "            \n",
    "                self.public_optimizer.optimizer.zero_grad()\n",
    "                p_output = self.public(z)\n",
    "                p_prob = self.softmaxlayer(p_output)\n",
    "                p_loss = self.nll_loss(torch.log(p_prob+1e-16), self.public_labels)    \n",
    "                \n",
    "            # Loss =====================================\n",
    "            if privacy_flag:\n",
    "                sensitive_labels = data[3] if len(data) == 4 else self.online_find_labels(self.labels, self.sensitive_classes)\n",
    "                self.sensitive_labels.resize_(sensitive_labels.size()).copy_(sensitive_labels)     \n",
    "                \n",
    "                self.discriminator_optimizer.optimizer.zero_grad()\n",
    "                d_output = self.discriminator(z)\n",
    "                d_prob = self.softmaxlayer(d_output)\n",
    "                \n",
    "                # Calculate for private task entropy/log liklihood\n",
    "                if arl_setting == 'maxent-arl':\n",
    "                    entropy_loss = -self.entropy_loss(d_prob)\n",
    "                elif arl_setting == 'ml-arl':\n",
    "                    entropy_loss = self.nll_loss(torch.log(d_prob+1e-16), self.sensitive_labels)\n",
    "                else:\n",
    "                    raise Exception(\"Invalid ARL.\")\n",
    "                s_loss = -entropy_loss\n",
    "            \n",
    "            # Combined loss to update SSD (+ public task)\n",
    "            if privacy_flag:\n",
    "                if public_flag:\n",
    "                    loss = (1-self.alpha)*(p_loss) + self.alpha*s_loss + ssd_loss\n",
    "                else:\n",
    "                    loss = (1-self.alpha)*(ssd_loss) + self.alpha*s_loss\n",
    "            else:\n",
    "                loss = ssd_loss\n",
    "\n",
    "            # Backprop ==================================\n",
    "            self.optimizer.optimizer.zero_grad()  \n",
    "            loss.backward()\n",
    "            if public_flag: _, _, _ = self.public_optimizer.step_all()                \n",
    "            enc_grad_norm, self.grad_norm, shrinkage = self.optimizer.step_all()\n",
    "                \n",
    "            # 2. Train Discriminator ====================\n",
    "            if privacy_flag: \n",
    "                d_loss, _ = self.train_net(net = self.discriminator, \n",
    "                                           net_optim = self.discriminator_optimizer,\n",
    "                                           net_input =z.detach(), \n",
    "                                           net_labels = self.sensitive_labels)    \n",
    "        \n",
    "            # 3. Save and Show Results ==================\n",
    "            self.running_loss += loss.item() / debug_steps\n",
    "            self.running_ssd_loss += ssd_loss.item() / debug_steps\n",
    "            self.running_regression_loss += reg_loss.item()  / debug_steps\n",
    "            self.running_classification_loss += class_loss.item() / debug_steps\n",
    "            self.report_grad_norm += self.grad_norm / debug_steps\n",
    "            if privacy_flag: \n",
    "                self.running_discriminator_loss += d_loss.item() / debug_steps\n",
    "                self.running_discriminator_entropy += entropy_loss.item() /debug_steps\n",
    "                \n",
    "            if public_flag:\n",
    "                self.running_public_loss += p_loss.item() / debug_steps\n",
    "            \n",
    "            #  Show the average results\n",
    "            if i and i % debug_steps == 0:\n",
    "                self.log(f\"Epoch:{epoch:02d}, Step:{i}, \" +\n",
    "                             f\"Loss:{self.running_loss:.4f}, \" +\n",
    "                             f\"SSD Loss:{self.running_ssd_loss:7.4f} [\" +\n",
    "                             f\"Reg:{self.running_regression_loss:.4f}, \" +\n",
    "                             f\"Class:{self.running_classification_loss:.4f}], \" + \n",
    "                             f\"ARL Loss:{self.running_discriminator_entropy:.4f}, \" + \n",
    "                             f\"D Loss:{self.running_discriminator_loss:.4f}, \" + \n",
    "                             f\"P Loss:{self.running_public_loss:.4f}, \" +\n",
    "                             f\"Grad Norm:{self.report_grad_norm:.4f}\"\n",
    "                            )\n",
    "                self.meters_reset()\n",
    "\n",
    "                # for param in net.classification_headers.parameters():\n",
    "                #     print(f\"Classification:{param[0][0]}\")\n",
    "                #     break                \n",
    "    \n",
    "    def test(self, criterion, d_loc, privacy_flag = False, public_flag=False):\n",
    "        \n",
    "        self.net.eval()\n",
    "        if privacy_flag: self.discriminator.eval()\n",
    "        if public_flag: self.public.eval()\n",
    "        self.meters_reset()\n",
    "        num = 0\n",
    "        self.net.test = True\n",
    "\n",
    "        for i, data in enumerate(self.test_loader):\n",
    "\n",
    "            num += 1\n",
    "            if i%10 == 0: print(end='.')\n",
    "            self.images.resize_(data[0].size()).copy_(data[0])\n",
    "            self.boxes.resize_(data[1].size()).copy_(data[1])\n",
    "            self.labels.resize_(data[2].size()).copy_(data[2])\n",
    "\n",
    "            # Sensitive label\n",
    "            \n",
    "            #  Feedforward\n",
    "            with torch.no_grad():\n",
    "                confidence, locations, z = self.net(self.images, d_loc)\n",
    "                class_loss, reg_loss = criterion(confidence, locations, self.labels, self.boxes)\n",
    "                loss = class_loss + reg_loss\n",
    "                \n",
    "                if privacy_flag:\n",
    "                    sensitive_labels = data[3] if len(data) == 4 else self.online_find_labels(self.labels, self.sensitive_classes)\n",
    "                    self.sensitive_labels.resize_(sensitive_labels.size()).copy_(sensitive_labels)   \n",
    "                    d_output = self.discriminator(z)\n",
    "                    d_prob = self.softmaxlayer(d_output)\n",
    "                    entropy_loss = -self.entropy_loss(d_prob)\n",
    "                    d_loss = self.nll_loss(torch.log(d_prob+1e-16), self.sensitive_labels)\n",
    "                    \n",
    "                if public_flag:\n",
    "                    public_labels = data[4] if len(data) == 5 else self.online_find_labels(self.labels, self.public_classes)\n",
    "                    self.public_labels.resize_(public_labels.size()).copy_(public_labels)     \n",
    "                    z = self.public(z)\n",
    "                    p_prob = self.softmaxlayer(z)\n",
    "                    p_entropy_loss = -self.entropy_loss(p_prob)\n",
    "                    p_loss = self.nll_loss(torch.log(p_prob+1e-16), self.public_labels)\n",
    "\n",
    "            #  Save numerical results\n",
    "            self.running_loss += loss.item()\n",
    "            self.running_regression_loss += reg_loss.item()\n",
    "            self.running_classification_loss += class_loss.item()\n",
    "            if privacy_flag:\n",
    "                self.running_discriminator_loss += d_loss.item()\n",
    "                self.running_discriminator_entropy += entropy_loss.item()\n",
    "            if public_flag:\n",
    "                self.running_public_loss += p_loss.item()\n",
    "\n",
    "        self.net.test = False\n",
    "\n",
    "        return (self.running_loss / num, self.running_regression_loss / num, self.running_classification_loss / num, self.running_discriminator_loss / num, \n",
    "                self.running_discriminator_entropy / num, self.running_public_loss / num)\n",
    "    \n",
    "    \n",
    "    def arl_attack(self, criterion, attacker_loc, attack_criterion=None, debug_steps=40, epoch=-1, verbose=False, public_flag=False):\n",
    "        ''' ===================================================================================\n",
    "        Main Algorithm:\n",
    "            1. Train encoder and decoder with discriminator loss\n",
    "            2. Train discriminator\n",
    "        ======================================================================================== '''\n",
    "        self.net.eval()\n",
    "        self.discriminator.train(True)\n",
    "        self.meters_reset()\n",
    "\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "\n",
    "            # Prepare data\n",
    "            if i%10 == 0 and i: print(end='.')\n",
    "            self.images.resize_(data[0].size()).copy_(data[0])\n",
    "            self.boxes.resize_(data[1].size()).copy_(data[1])\n",
    "            self.labels.resize_(data[2].size()).copy_(data[2])\n",
    "            sensitive_labels = data[3] if len(data) == 4 else self.online_find_labels(self.labels, self.sensitive_classes)\n",
    "            self.sensitive_labels.resize_(sensitive_labels.size()).copy_(sensitive_labels)   \n",
    "\n",
    "            # 1. Train Encoder + Predictor =============\n",
    "            with torch.no_grad():\n",
    "                confidence, locations, z = self.net(self.images, attacker_loc)\n",
    "                class_loss, reg_loss = criterion(confidence, locations, self.labels, self.boxes)\n",
    "                ssd_loss = class_loss + reg_loss\n",
    "                \n",
    "                \n",
    "            d_loss, self.grad_norm = self.train_net(net=self.discriminator, \n",
    "                                                    net_optim=self.discriminator_optimizer,\n",
    "                                                    net_input=z.detach(), \n",
    "                                                    net_labels=self.sensitive_labels)\n",
    "            \n",
    "#             if public_flag:\n",
    "#                 public_labels = data[4] if len(data) == 5 else self.online_find_labels(self.labels, self.public_classes)\n",
    "#                 self.public_labels.resize_(public_labels.size()).copy_(public_labels)     \n",
    "            \n",
    "#                 self.public_optimizer.optimizer.zero_grad()\n",
    "#                 p_output = self.public(z)\n",
    "#                 p_prob = self.softmaxlayer(p_output)\n",
    "#                 p_loss = self.nll_loss(torch.log(p_prob+1e-16), self.public_labels)   \n",
    "\n",
    "            # 3. Save and Show Results ==================\n",
    "            self.running_loss += d_loss.item() / debug_steps\n",
    "            self.running_ssd_loss += ssd_loss.item() / debug_steps\n",
    "            self.running_regression_loss += reg_loss.item()  / debug_steps\n",
    "            self.running_classification_loss += class_loss.item() / debug_steps\n",
    "            self.report_grad_norm += self.grad_norm / debug_steps\n",
    "            \n",
    "            #  Show the average results\n",
    "            if i and i % debug_steps == 0:\n",
    "                self.log(f\"Epoch:{epoch:02d}, Step:{i:3d}, \" +\n",
    "                             f\"Attacker Loss:{self.running_loss:.4f}, \" +\n",
    "                             f\"SSD Loss:{self.running_ssd_loss:7.4f} [\" +\n",
    "                             f\"Reg:{self.running_regression_loss:.4f}, \" +\n",
    "                             f\"Class:{self.running_classification_loss:.4f}], \" + \n",
    "                             f\"Grad Norm:{self.report_grad_norm:.4f}\"\n",
    "                            )\n",
    "                self.meters_reset()\n",
    "\n",
    "                # for param in net.classification_headers.parameters():\n",
    "                #     print(f\"Classification:{param[0][0]}\")\n",
    "                #     break                \n",
    "        \n",
    "    def test_attack(self, criterion, attacker_loc, privacy_flag = True):\n",
    "        \n",
    "        self.net.eval()\n",
    "        self.discriminator.eval()\n",
    "        self.meters_reset()\n",
    "        num = 0\n",
    "        self.net.test = True\n",
    "\n",
    "        for i, data in enumerate(self.test_loader):\n",
    "\n",
    "            num += 1\n",
    "            if i%10 == 0: print(end='.')\n",
    "            self.images.resize_(data[0].size()).copy_(data[0])\n",
    "            self.boxes.resize_(data[1].size()).copy_(data[1])\n",
    "            self.labels.resize_(data[2].size()).copy_(data[2])\n",
    "\n",
    "            # Sensitive label\n",
    "            sensitive_labels = data[3] if len(data) == 4 else self.online_find_labels(self.labels, self.sensitive_classes)\n",
    "            self.sensitive_labels.resize_(sensitive_labels.size()).copy_(sensitive_labels)   \n",
    "            \n",
    "            #  Feedforward\n",
    "            with torch.no_grad():\n",
    "                confidence, locations, z = self.net(self.images, attacker_loc)\n",
    "                class_loss, reg_loss = criterion(confidence, locations, self.labels, self.boxes)\n",
    "                loss = class_loss + reg_loss\n",
    "                \n",
    "                d_output = self.discriminator(z)\n",
    "                d_prob = self.softmaxlayer(d_output)\n",
    "                d_loss = self.nll_loss(torch.log(d_prob+1e-16), self.sensitive_labels)\n",
    "                \n",
    "                entropy_loss = -self.entropy_loss(d_prob)\n",
    "                s_loss = -entropy_loss \n",
    "\n",
    "                #  Loss\n",
    "\n",
    "\n",
    "            #  Save numerical results\n",
    "            self.running_loss += loss.item()\n",
    "            self.running_regression_loss += reg_loss.item()\n",
    "            self.running_classification_loss += class_loss.item()\n",
    "            self.running_discriminator_loss += d_loss.item()\n",
    "            self.running_discriminator_entropy += entropy_loss.item()\n",
    "\n",
    "                 \n",
    "\n",
    "        self.net.test = False\n",
    "\n",
    "        return self.running_loss/num, self.running_regression_loss/num, self.running_classification_loss/num, self.running_discriminator_loss/num, self.running_discriminator_entropy/num\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65sKwaNUAr-_"
   },
   "source": [
    "## main\n",
    "\n",
    "Checkpoint Folder: https://drive.google.com/drive/u/1/folders/1trRWtHV_io4EDScepki1Q1RS_YewKdTA\n",
    "\n",
    "Argparse in Jupyternotebook: https://zhuanlan.zhihu.com/p/145720581\n",
    "\n",
    "Restore: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Gi5mO_LRxxWW"
   },
   "outputs": [],
   "source": [
    "def create_dir():\n",
    "    experiment_time = 1\n",
    "    testing_dir = f\"/home/hjchris/research/mitigating/chris/pascal_ckpts/{today}/{today}-{experiment_time}\"\n",
    "    while (os.path.exists(testing_dir) and len([name for name in os.listdir(testing_dir) if os.path.isfile(os.path.join(testing_dir, name))]) != 0):\n",
    "        experiment_time += 1\n",
    "        testing_dir = f\"/home/hjchris/research/mitigating/chris/pascal_ckpts/{today}/{today}-{experiment_time}\"\n",
    "    \n",
    "    return testing_dir, experiment_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "l5T6xuuGS4ok"
   },
   "outputs": [],
   "source": [
    "class TrainingSetup:\n",
    "    def __init__(self, pretrained_encoder= None, log=print):\n",
    "\n",
    "\n",
    "        self.log=log\n",
    "        # network hyperparameters\n",
    "        self.learning_rate = 1e-2\n",
    "        self.discriminator_lr = 1e-4\n",
    "        self.public_lr = 1e-4\n",
    "        self.encoder_lr = 1e-4\n",
    "        self.base_net_lr =  self.learning_rate\n",
    "        self.extra_layers_lr = self.learning_rate\n",
    "        self.num_classes = 21\n",
    "        \n",
    "        # ARL setting\n",
    "        self.privacy_flag = True\n",
    "        self.public_flag = False\n",
    "        self.attack_flag = False\n",
    "        self.save = True\n",
    "        self.saving_more = True\n",
    "        self.continue_training = False\n",
    "\n",
    "        # encoder setting\n",
    "        self.public_headers = None\n",
    "        self.public_optimizer = None\n",
    "        self.public_scheduler = None\n",
    "        \n",
    "        self.discriminator_headers = None\n",
    "        self.discriminator_optimizer = None\n",
    "        self.discriminator_scheduler = None\n",
    "        \n",
    "        self.encoder_flag=False\n",
    "        self.pretrained_encoder = pretrained_encoder\n",
    "\n",
    "        # network general setting        \n",
    "        self.last_epoch = -1\n",
    "        self.num_epochs = 201\n",
    "        self.loading_net = \"basenet\"\n",
    "        self.scheduler_type = 'cosine'\n",
    "\n",
    "        # optimizer setting\n",
    "        self.opt_type = 'sgd'\n",
    "        self.max_grad_norm = 6\n",
    "        self.verbose = False\n",
    "        self.t_max = 200\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 0.0005\n",
    "        self.min_loss = -10000.0\n",
    "        \n",
    "        self.timer = Timer()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            train_log.info(\"Use cuda:0\")\n",
    "    \n",
    "    def set_directory(self):\n",
    "        save_path, experiment_time = create_dir()\n",
    "        self.log(f\"=\"*45 + f\" Training Session {today}-{experiment_time} \" + f\"=\"*45)\n",
    "        \n",
    "        if not os.path.exists(save_path): os.mkdir(save_path)\n",
    "        self.checkpoint_folder = save_path\n",
    "        \n",
    "        if self.save: \n",
    "            self.log(f\"Model will be stored at {self.checkpoint_folder}\")\n",
    "    \n",
    "    def build_discriminator(self, d_loc):\n",
    "        create_discriminator = Create_Discriminator()\n",
    "        return create_discriminator.build(d_loc)\n",
    "    \n",
    "    def build_network(self):\n",
    "        self.log(\"Build SSD.\")\n",
    "        create_net = create_mobilenetv2_ssd_lite(num_classes = self.num_classes, width_mult = 1.0)\n",
    "        return create_net.create_SSD()\n",
    "\n",
    "    def build_init(self, load_path):\n",
    "        timer = Timer()\n",
    "        timer.start(\"Load Model\")\n",
    "        \n",
    "        # load mbovilenetv2 base parameters\n",
    "        if \"mb2-imagenet-71_8.pth\" in load_path:\n",
    "            self.log(f\"Initialize SSD basenet from: {load_path}\")\n",
    "            self.net.init_base_net(load_path)\n",
    "            self.log(f'Took {timer.end(\"Load Model\"):.2f} seconds to load mobilenet into the model.')\n",
    "\n",
    "        else:\n",
    "            self.load_checkpoint(load_path)\n",
    "        \n",
    "    def build_rest(self):\n",
    "        if not self.save: self.log(f\"Not Saving model.\")\n",
    "\n",
    "    def build_scheduler(self, optimizer, name = 'SSD', privacy_flag = False):\n",
    "        \n",
    "        if self.scheduler_type == \"multi-step\":\n",
    "            self.log(\"Use MultiStepLR scheduler.\")\n",
    "            milestones = [int(v.strip()) for v in \"80,100\".split(\",\")]\n",
    "            return MultiStepLR(optimizer, milestones=milestones, gamma=0.1, last_epoch=last_epoch)\n",
    "        else:\n",
    "            self.log(name + f\" build [{self.scheduler_type}] CosineAnnealingLR scheduler. Max iter.={self.t_max}, last epoch={self.last_epoch}.\")\n",
    "            return CosineAnnealingLR(optimizer, self.t_max, last_epoch=self.last_epoch)\n",
    "\n",
    "    def build_criterion(self):\n",
    "        self.log(f\"Build MultiboxLoss. Use mobilnetv1 SSD configuration.\")\n",
    "        config = mobilenetv1_ssd_config\n",
    "        return MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3, center_variance=0.1, size_variance=0.2, device=DEVICE)\n",
    "\n",
    "    def build_optim(self, parameters=None, name='SSD', learning_rate=1e-4, privacy_flag = False, opt_type = 'sgd'):\n",
    "        self.log(name +  f\" build {opt_type} optimizer in Optim, momentum={self.momentum}, \" + \n",
    "                     f\"weight_decay={self.weight_decay}, \" + \n",
    "                     f\"max gradient norm={self.max_grad_norm}.\")   \n",
    "        params=[]\n",
    "        \n",
    "        if not privacy_flag:\n",
    "            self.log(\"Use ssd parameters.\")\n",
    "            params = [{'params': self.net.base_net.parameters(),'lr': self.base_net_lr},\n",
    "                      {'params': itertools.chain(self.net.source_layer_add_ons.parameters(), self.net.extras.parameters()),'lr': self.extra_layers_lr},\n",
    "                      {'params': itertools.chain(self.net.regression_headers.parameters(), self.net.classification_headers.parameters())}\n",
    "                     ]\n",
    "\n",
    "            # Encoder Parameters\n",
    "            if self.net.encoder_headers:\n",
    "                self.log(f\"Use extra encoder parameters.\")\n",
    "                params.append({'params': self.net.encoder_headers.parameters(),'lr': self.encoder_lr})\n",
    "                encoder_params = self.net.encoder_headers.parameters()\n",
    "            else:\n",
    "                encoder_params = self.net.base_net.parameters()\n",
    "                \n",
    "        else:\n",
    "            params.append({'params': parameters,'lr': learning_rate})\n",
    "            encoder_params = []\n",
    "\n",
    "        return Optim(params = params, \n",
    "                     method = opt_type, \n",
    "                     enc_params = encoder_params,\n",
    "                     max_grad_norm = self.max_grad_norm, \n",
    "                     lr=self.learning_rate,\n",
    "                     sgd_momentum=self.momentum,\n",
    "                     sgd_weight_decay=self.weight_decay,\n",
    "                     privacy_flag=privacy_flag\n",
    "                     )\n",
    "    \n",
    "    # ==========================================================================\n",
    "    #                               Main Logic\n",
    "    # ==========================================================================\n",
    "    def build(self, load_path, privacy_flag, public_flag, d_loc, opt_type='sgd', discriminator_opt_type='adam', is_attack=False):\n",
    "        \n",
    "        self.public_flag = public_flag\n",
    "        self.privacy_flag = privacy_flag\n",
    "        self.set_directory()\n",
    "\n",
    "        # create SSD [encoder and decoder]\n",
    "        self.net = self.build_network()\n",
    "        self.net.init()\n",
    "        self.log(\"Xavier Initialization for SSD.\")\n",
    "        self.build_init(load_path)\n",
    "        self.optimizer = self.build_optim(privacy_flag = False, opt_type=opt_type)\n",
    "        self.scheduler = self.build_scheduler(self.optimizer.optimizer, privacy_flag=False)\n",
    "        \n",
    "        # public task\n",
    "        if self.public_flag:\n",
    "            self.public_flag = public_flag\n",
    "            self.public_headers = self.build_discriminator(d_loc)\n",
    "            self.public_optimizer = self.build_optim(name='Public',\n",
    "                                                     parameters = self.public_headers.parameters(),\n",
    "                                                     learning_rate = self.public_lr,\n",
    "                                                     privacy_flag = True, \n",
    "                                                     opt_type = discriminator_opt_type)\n",
    "            self.public_scheduler = self.build_scheduler(name='Public',\n",
    "                                                         optimizer=self.public_optimizer.optimizer, \n",
    "                                                         privacy_flag=True)\n",
    "            self.public_headers.to(DEVICE)\n",
    "        \n",
    "        # private task\n",
    "        if self.privacy_flag:   \n",
    "            build_name = 'Attacker' if is_attack else 'Discrimiantor'\n",
    "            self.discriminator_headers = self.build_discriminator(d_loc)\n",
    "            self.discriminator_optimizer = self.build_optim(name=build_name,\n",
    "                                                            parameters = self.discriminator_headers.parameters(),\n",
    "                                                            learning_rate = self.discriminator_lr,\n",
    "                                                            privacy_flag=True, \n",
    "                                                            opt_type=discriminator_opt_type)\n",
    "            self.discriminator_scheduler = self.build_scheduler(name=build_name,\n",
    "                                                                optimizer = self.discriminator_optimizer.optimizer, \n",
    "                                                                privacy_flag=True)\n",
    "            self.discriminator_headers.to(DEVICE)\n",
    "        \n",
    "        # loss function\n",
    "        self.criterion = self.build_criterion()\n",
    "        \n",
    "        # loading parameters\n",
    "        self.build_rest()\n",
    "        self.net.to(DEVICE)\n",
    "    # ==========================================================================\n",
    "    #                             Main Logic End\n",
    "    # ==========================================================================\n",
    "    \n",
    "    def load_checkpoint(self, load_path):\n",
    "        self.log(f\"Load SSD from: {load_path}\")\n",
    "        self.checkpoint = torch.load(load_path, map_location=lambda storage, loc: storage)\n",
    "        self.net.init_from_pretrained_ssd(load_path, log=train_log.info)  \n",
    "        \n",
    "        self.privacy_flag = self.checkpoint['privacy_flag']\n",
    "        self.max_grad_norm = self.checkpoint['max_grad_norm']\n",
    "        self.log(f\"privacy_flag={self.privacy_flag}, max_grad_norm={self.max_grad_norm}\")\n",
    "        \n",
    "        if self.checkpoint['privacy_flag']:\n",
    "            self.alpha = self.checkpoint['alpha']\n",
    "            self.sensitive_classes = self.checkpoint['sensitive_classes']\n",
    "            self.discriminator_loc = self.checkpoint['discriminator_loc']\n",
    "            self.log(f\"alpha={self.alpha[0]}, sensitive_classes={self.sensitive_classes}, discriminator_loc={self.discriminator_loc}\")\n",
    "        else:\n",
    "            self.alpha = 0.0\n",
    "            self.sensitive_classes = [15]\n",
    "            \n",
    "    \n",
    "    def attack(self, train_loader, val_loader, attacker_loc, verbose=False, val_epoch=5, skip_train=False, previous_model=''): \n",
    "        ''' ====================================================================\n",
    "        ARL Attack. \n",
    "        The discriminator is used as the attacker.\n",
    "        \n",
    "        \n",
    "        ==================================================================== '''\n",
    "        self.log(f\"train loader={len(train_loader)}, validation loader={len(val_loader)}\")    \n",
    "        self.log(f\"Start attack the model.\")\n",
    "        attack_model = previous_model\n",
    "        \n",
    "        nets = [self.net, self.discriminator_headers, self.public_headers]\n",
    "        optimizers = [None, self.discriminator_optimizer, None]\n",
    "        schedulers = [None, self.discriminator_scheduler, None]\n",
    "        \n",
    "        train_net = Maxtrain_Network(nets, optimizers, train_loader, val_loader, self.alpha, self.sensitive_classes, log=self.log)\n",
    "        \n",
    "        for epoch in range(self.last_epoch + 1, self.num_epochs):\n",
    "                                     \n",
    "            if not skip_train:\n",
    "                train_net.arl_attack(self.criterion, \n",
    "                                     attacker_loc, \n",
    "                                     debug_steps=40, \n",
    "                                     epoch=epoch)\n",
    "                for scdlr in schedulers:\n",
    "                    scdlr.step() if scdlr else None\n",
    "            \n",
    "            if epoch % val_epoch == 0 or epoch == self.num_epochs - 1 :                \n",
    "                val_loss, val_reg_loss, val_class_loss, val_loss_dis, val_ent = train_net.test_attack(self.criterion, attacker_loc, self.privacy_flag)\n",
    "                self.log(f\"Epoch:{epoch:02d}, \" +\n",
    "                             f\"Validation Loss:{val_loss + val_loss_dis:.4f}/{val_loss:.4f}, \" +\n",
    "                             f\"Reg Loss:{val_reg_loss:.4f}, \" +\n",
    "                             f\"Class Loss:{val_class_loss:.4f}, \" +\n",
    "                             f\"D Loss:{val_loss_dis:.4f}, \" + \n",
    "                             f\"D Entropy:{val_ent:.4f}\"\n",
    "                             )                    \n",
    "                #  Save\n",
    "                if self.save:\n",
    "                    model_name = f\"{'mb2-ssd-lite'}-Attack-Ep{epoch:03d}-FM{attacker_loc}-Loss-{val_loss:.4f}+{val_loss_dis:.4f}-Ent-{val_ent:.4f}.pth\"\n",
    "                    model_path = os.path.join(self.checkpoint_folder, model_name)\n",
    "                    self.net.save_attack(privacy_flag=self.privacy_flag, \n",
    "                                         public_flag=self.public_flag,\n",
    "                                         alpha = self.alpha, \n",
    "                                         max_grad_norm = self.max_grad_norm, \n",
    "                                         epoch = epoch,\n",
    "                                         optimizers = optimizers,\n",
    "                                         schedulers = schedulers, \n",
    "                                         ssd_loss = val_loss, \n",
    "                                         sensitive_classes = self.sensitive_classes,\n",
    "                                         entropy = val_ent,\n",
    "                                         attacker = self.discriminator_headers,\n",
    "                                         attacker_loss = val_loss_dis, \n",
    "                                         attacker_loc = attacker_loc,\n",
    "                                         model_path = model_path,\n",
    "                                         name = attack_model\n",
    "                                        )\n",
    "                    self.log(f\"Save models at: ~{model_path[52:]}\")\n",
    "                    if os.path.exists(previous_model): os.remove(previous_model)\n",
    "                    previous_model = model_path\n",
    "    \n",
    "    \n",
    "    def train(self, train_loader, val_loader, d_loc = 14, public_classes = [7], sensitive_classes=[15], alpha=1.0, verbose=False, val_epoch=5, \n",
    "              skip_train=False, previous_model='', arl_setting=None):\n",
    "        ''' ======================================================================\n",
    "        ARL Training\n",
    "        \n",
    "        ========================================================================== '''  \n",
    "\n",
    "        if self.privacy_flag:\n",
    "            self.log(f\"Discriminator location={d_loc}, Alpha={alpha}, Sensitive classes={sensitive_classes}, Arl_setting={arl_setting}\")\n",
    "        if self.public_flag:\n",
    "            self.log(f\"Public classes={public_classes}\")            \n",
    "\n",
    "        self.log(f\"train loader={len(train_loader)}, validation loader={len(val_loader)}\")    \n",
    "        self.log(f\"Start training from epoch {self.last_epoch + 1}.\") \n",
    "        \n",
    "        nets = [self.net, self.discriminator_headers, self.public_headers]\n",
    "        optimizers = [self.optimizer, self.discriminator_optimizer, self.public_optimizer]\n",
    "        schedulers = [self.scheduler, self.discriminator_scheduler, self.public_scheduler]\n",
    "        \n",
    "        if self.privacy_flag:\n",
    "            alpha = torch.tensor([alpha*1.0], requires_grad=True)\n",
    "\n",
    "        train_net = Maxtrain_Network(nets, optimizers, train_loader, val_loader, alpha, sensitive_classes, public_classes, log=self.log)\n",
    "\n",
    "        for epoch in range(self.last_epoch + 1, self.num_epochs):       \n",
    "            \n",
    "            if not skip_train:\n",
    "                train_net.arl_train(self.criterion, \n",
    "                                    privacy_flag = self.privacy_flag, \n",
    "                                    public_flag  = self.public_flag, \n",
    "                                    d_loc=d_loc,\n",
    "                                    debug_steps=100, \n",
    "                                    epoch=epoch, \n",
    "                                    verbose=verbose,\n",
    "                                    arl_setting = arl_setting,\n",
    "                                   )\n",
    "                \n",
    "                for scdlr in schedulers:\n",
    "                    scdlr.step() if scdlr else None\n",
    "\n",
    "            # Evaluation\n",
    "            if epoch % val_epoch == 0 or epoch == self.num_epochs - 1 :                \n",
    "\n",
    "                val_loss, val_reg_loss, val_class_loss, val_d_loss, val_d_ent, val_p_loss = train_net.test(self.criterion,  \n",
    "                                                                                                           d_loc=d_loc,\n",
    "                                                                                                           privacy_flag=self.privacy_flag,\n",
    "                                                                                                           public_flag  = self.public_flag,\n",
    "                                                                                                          )\n",
    "                self.log(f\"Epoch:{epoch:02d}, \" +\n",
    "                             f\"Validation Loss:{val_loss + val_d_ent:.4f} [\" +\n",
    "                             f\"Reg Loss:{val_reg_loss:.4f}, \" +\n",
    "                             f\"Class Loss:{val_class_loss:.4f}], \" +\n",
    "                             f\"Entropy:{val_d_ent:.4f}, \" +\n",
    "                             f\"D Loss:{val_d_loss:.4f}, \" +\n",
    "                             f\"P Loss:{val_p_loss:.4f}\"\n",
    "                             ) \n",
    "                \n",
    "                if self.save:\n",
    "                    model_name = f\"{'mb2-ssd-lite'}-Ep{epoch:03d}\"\n",
    "                    if self.privacy_flag:\n",
    "                        model_name += f\"-FM{d_loc}-A{alpha.data[0]:.1f}\"\n",
    "                    model_name += f\"-Loss-{val_loss:.4f}\"\n",
    "                    if self.privacy_flag:\n",
    "                        model_name += f\"+{val_d_ent:.4f}-DL-{val_d_loss:.4f}\"\n",
    "                    if self.public_flag:\n",
    "                        model_name += f\"-PL-{val_p_loss:.4f}\"\n",
    "                    model_name += f\".pth\"\n",
    "                        \n",
    "                        \n",
    "                    model_path = os.path.join(self.checkpoint_folder, model_name)\n",
    "                    \n",
    "                    self.net.save(privacy_flag = self.privacy_flag, \n",
    "                                  public_flag = self.public_flag,\n",
    "                                  alpha = alpha, \n",
    "                                  max_grad_norm = self.max_grad_norm, \n",
    "                                  epoch = epoch, \n",
    "                                  optimizers = optimizers, \n",
    "                                  schedulers = schedulers, \n",
    "                                  val_loss = val_loss, \n",
    "                                  val_d_ent = val_d_ent, \n",
    "                                  val_d_loss = val_d_loss,\n",
    "                                  sensitive_classes = sensitive_classes,\n",
    "                                  discriminator_loc = d_loc,\n",
    "                                  discriminator= self.discriminator_headers,\n",
    "                                  model_path = model_path,\n",
    "                                  public=self.public_headers,\n",
    "                                  val_p_loss = val_p_loss,\n",
    "                                  public_classes = public_classes,\n",
    "                                  arl_setting = arl_setting\n",
    "                                 )\n",
    "                    \n",
    "                    self.log(f\"Save models at: ~{model_path[52:]}\")\n",
    "                    if os.path.exists(previous_model): os.remove(previous_model)\n",
    "                    previous_model = model_path\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ssd_file(checkpoint_folder):\n",
    "    \n",
    "    filenames=[]\n",
    "    for filename in os.listdir(checkpoint_folder):\n",
    "        if \"pth\" in filename:\n",
    "            filenames.append(filename)\n",
    "            \n",
    "    ssd_path = checkpoint_folder + filenames[0]\n",
    "    epoch = filenames[0].split(\"Ep\")[1][:3]\n",
    "    eval_path = checkpoint_folder + f\"evaluation_{epoch}/\"\n",
    "    \n",
    "    if not os.path.exists(eval_path):os.mkdir(eval_path)\n",
    "        \n",
    "    print(f\"ssd path: {ssd_path}\")\n",
    "    print(f\"eval path: {eval_path}\")\n",
    "    return ssd_path, eval_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def write_doc(name, mode, dictionary, method=None, message=None):\n",
    "    time = datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    with open(\"chris/pascal_ckpts/document.txt\", 'a') as file:\n",
    "        file.write(f\"{time} - File={name},\\tTask={mode},\\t\")  \n",
    "        for item in dictionary.items():\n",
    "                file.write(f\"{item[0]}={item[1]},\\t \")\n",
    "                if item[0] == 'privacy_flag' and item[1] == False: break\n",
    "                if item[0] == 'public_flag' and item[1] == False: break\n",
    "                \n",
    "        if message:\n",
    "                file.write(\"msg=(\" + str(message) + \")\\t\")\n",
    "        file.write(\"end\\n\")\n",
    "        \n",
    "def write_doc_end(name, mode):\n",
    "    time = datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    with open(\"chris/pascal_ckpts/document.txt\", 'a') as file:\n",
    "        file.write(f\"{time} - File {name}   {mode} ends.\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7KRfgkMbDLn"
   },
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1:**aeroplane**\n",
    "2:**bicycle**\n",
    "3:**bird**\n",
    "4:**boat**\n",
    "5:**bottle**\n",
    "6:**bus**\n",
    "7:**car**\n",
    "8:**cat**\n",
    "9:**chair**\n",
    "10:**cow**\n",
    "11:**diningtable**\n",
    "12:**dog**\n",
    "13:**horse**\n",
    "14:**motorbike**\n",
    "15:**person**\n",
    "16:**pottedplant**\n",
    "17:**sheep**\n",
    "18:**sofa**\n",
    "19:**train**\n",
    "20:**tvmonitor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJabYVCgoIGW",
    "outputId": "805cc83a-7f5d-4fc4-863f-d2ce5a486ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-02 10:59:09,466 - train - INFO - Using Original VOCdataset functions? Training:True, Testing:True.\n",
      "2022-01-02 10:59:09,469 - train - INFO - Prepare training datasets\n",
      "No labels file, using default VOC classes.\n",
      "No labels file, using default VOC classes.\n",
      "No labels file, using default VOC classes.\n",
      "No labels file, using default VOC classes.\n",
      "2022-01-02 10:59:09,499 - train - INFO - Stored labels into file.\n",
      "2022-01-02 10:59:09,501 - train - INFO - Train data: 11584, loader: 362, batch_size=32, shuffle=True\n",
      "2022-01-02 10:59:09,502 - train - INFO - Train attack data : 4967, loader: 156, batch_size=32, shuffle=True\n",
      "2022-01-02 10:59:09,503 - train - INFO - Prepare Validation datasets.\n",
      "No labels file, using default VOC classes.\n",
      "No labels file, using default VOC classes.\n",
      "2022-01-02 10:59:09,514 - train - INFO - Valid data: 3466, loader: 109, batch_size=32, shuffle=False.\n",
      "2022-01-02 10:59:09,515 - train - INFO - Valid attack data: 1486, loader:47, batch_size=32, shuffle=False\n",
      "2022-01-02 10:59:09,517 - train - INFO - Use cuda:0\n",
      "2022-01-02 10:59:09,597 - train - INFO - ============================================= Training Session 0102_22-1 =============================================\n",
      "2022-01-02 10:59:09,599 - train - INFO - Model will be stored at /home/hjchris/research/mitigating/chris/pascal_ckpts/0102_22/0102_22-1\n",
      "2022-01-02 10:59:09,600 - train - INFO - Build SSD.\n",
      "2022-01-02 10:59:09,740 - train - INFO - Xavier Initialization for SSD.\n",
      "2022-01-02 10:59:09,741 - train - INFO - Initialize SSD basenet from: /home/hjchris/data/Pascal_VOC/mb2-imagenet-71_8.pth\n",
      "2022-01-02 10:59:09,784 - train - INFO - Took 0.04 seconds to load mobilenet into the model.\n",
      "2022-01-02 10:59:09,785 - train - INFO - SSD build sgd optimizer in Optim, momentum=0.9, weight_decay=0.0005, max gradient norm=6.\n",
      "2022-01-02 10:59:09,786 - train - INFO - Use ssd parameters.\n",
      "2022-01-02 10:59:09,789 - train - INFO - SSD build [cosine] CosineAnnealingLR scheduler. Max iter.=200, last epoch=-1.\n",
      "2022-01-02 10:59:14,796 - train - INFO - Discrimiantor build adam optimizer in Optim, momentum=0.9, weight_decay=0.0005, max gradient norm=6.\n",
      "2022-01-02 10:59:14,797 - train - INFO - Discrimiantor build [cosine] CosineAnnealingLR scheduler. Max iter.=200, last epoch=-1.\n",
      "2022-01-02 10:59:14,799 - train - INFO - Build MultiboxLoss. Use mobilnetv1 SSD configuration.\n",
      "2022-01-02 10:59:14,814 - train - INFO - Discriminator location=18, Alpha=0.7, Sensitive classes=[15], Arl_setting=maxent-arl\n",
      "2022-01-02 10:59:14,814 - train - INFO - train loader=362, validation loader=109\n",
      "2022-01-02 10:59:14,815 - train - INFO - Start training from epoch 0.\n",
      "..........2022-01-02 10:59:44,914 - train - INFO - Epoch:00, Step:100, Loss:3.2854, SSD Loss:12.5030 [Reg:3.1103, Class:9.3927], ARL Loss:0.6650, D Loss:0.7107, P Loss:0.0000, Grad Norm:6.2703\n",
      "..........2022-01-02 11:00:12,636 - train - INFO - Epoch:00, Step:200, Loss:1.8698, SSD Loss: 7.7795 [Reg:2.2718, Class:5.5077], ARL Loss:0.6629, D Loss:0.6418, P Loss:0.0000, Grad Norm:1.9998\n",
      "..........2022-01-02 11:00:40,140 - train - INFO - Epoch:00, Step:300, Loss:1.7310, SSD Loss: 7.2820 [Reg:2.0701, Class:5.2119], ARL Loss:0.6480, D Loss:0.6228, P Loss:0.0000, Grad Norm:1.9527\n",
      ".................2022-01-02 11:01:10,590 - train - INFO - Epoch:00, Validation Loss:7.4379 [Reg Loss:1.9387, Class Loss:4.8522], Entropy:0.6471, D Loss:0.6296, P Loss:0.0000\n",
      "2022-01-02 11:01:10,739 - train - INFO - Save models at: ~/0102_22/0102_22-1/mb2-ssd-lite-Ep000-FM18-A0.7-Loss-6.7908+0.6471-DL-0.6296.pth\n",
      "..........2022-01-02 11:01:40,695 - train - INFO - Epoch:01, Step:100, Loss:1.5599, SSD Loss: 6.7058 [Reg:1.8929, Class:4.8128], ARL Loss:0.6455, D Loss:0.6310, P Loss:0.0000, Grad Norm:2.1512\n",
      "..........2022-01-02 11:02:08,424 - train - INFO - Epoch:01, Step:200, Loss:1.4718, SSD Loss: 6.3894 [Reg:1.7748, Class:4.6146], ARL Loss:0.6357, D Loss:0.6276, P Loss:0.0000, Grad Norm:2.1064\n",
      "......."
     ]
    }
   ],
   "source": [
    "# dataload_folder = '/home/hjchris/data/Pascal_VOC'\n",
    "root_path = f\"/home/hjchris/data\"\n",
    "data_prep = Data_Preprocessing(log=train_log.info)\n",
    "data_prep.load_online(root_path)\n",
    "\n",
    "\n",
    "message = None\n",
    "public_flag_set = [False]\n",
    "arl_setting = ['ml-arl']\n",
    "arl_set = ['maxent-arl', 'ml-arl']\n",
    "locations = [18]\n",
    "\n",
    "attack_dates = [\"1221\",\"1221\",\"1221\",\"1221\",\"1221\",\"1221\",\"1221\",\"1221\",\"1221\",\"1221\",\"1221\",\"1221\",\"1221\"]\n",
    "attack_nums = [1, 1, 1, 1, 1, 2, 2, 2, 2, 2 ]\n",
    "attack_locs = [14, 18, 19, 20, 21, 14, 18, 19, 20, 21]\n",
    "\n",
    "\n",
    "todays_task_is_train = True\n",
    "\n",
    "if not todays_task_is_train:\n",
    "    print(\"Attacking:\")\n",
    "    for att in range(min(len(attack_dates), len(attack_nums))):\n",
    "        attack_date = attack_dates[att]\n",
    "        attack_num = attack_nums[att]\n",
    "        attack_loc = attack_locs[att]\n",
    "        print(f\"{attack_date}_21/{attack_date}_21-{attack_num}-loc-{attack_loc}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "if todays_task_is_train:\n",
    "    for pb in public_flag_set:\n",
    "        for arl_setting in arl_set:\n",
    "            for d_loc in locations:\n",
    "                train_dict ={'privacy_flag':True,\n",
    "                             'method': arl_setting,\n",
    "                             'alpha': 0.7,\n",
    "                             'd_loc': d_loc,\n",
    "                             'd_type': \"A\",\n",
    "                             'sensitive_classes':[15],\n",
    "                             'public_flag':pb,\n",
    "                             'public_classes':[7],\n",
    "                             'p_type': \"A\",\n",
    "                            }\n",
    "\n",
    "                arl_model = TrainingSetup(data_prep, log=train_log.info)\n",
    "\n",
    "                for run in range(1):\n",
    "\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    basenet_path = os.path.join(f\"{root_path}/Pascal_VOC\", f\"mb2-imagenet-71_8.pth\")\n",
    "                    arl_model.build(load_path = basenet_path,\n",
    "                                    d_loc = train_dict['d_loc'],\n",
    "                                    public_flag = train_dict['public_flag'],\n",
    "                                    privacy_flag = train_dict['privacy_flag']\n",
    "                                    )\n",
    "\n",
    "                    _, experiment_time = create_dir()\n",
    "                    write_doc(f\"{today}-{experiment_time}\", mode=\"train \", dictionary=train_dict, method=arl_setting, message=message)\n",
    "\n",
    "                    arl_model.train(data_prep.train_loader, \n",
    "                                    data_prep.val_loader,\n",
    "                                    arl_setting = train_dict['method'],\n",
    "                                    alpha = train_dict['alpha'],\n",
    "                                    d_loc = train_dict['d_loc'],\n",
    "                                    verbose = True, \n",
    "                                    public_classes = train_dict['public_classes'],\n",
    "                                    sensitive_classes = train_dict['sensitive_classes'], \n",
    "                                    val_epoch = 5,\n",
    "                                    skip_train = False\n",
    "                                    )\n",
    "                    write_doc_end(f\"{today}-{experiment_time}\", mode=\"train\")\n",
    "\n",
    "                \n",
    "else:\n",
    "    for att in range(min(len(attack_dates), len(attack_nums))):\n",
    "\n",
    "        attack_date = attack_dates[att]\n",
    "        attack_num = attack_nums[att]\n",
    "        attack_loc = attack_locs[att]\n",
    "        \n",
    "        attack_root = '/home/hjchris/research/mitigating/chris/pascal_ckpts/'\n",
    "        attack_path, _ = find_ssd_file(attack_root + f\"{attack_date}_21/{attack_date}_21-{attack_num}/\")\n",
    "\n",
    "        attack_dict ={'attack_model':f\"{attack_date}_21-{attack_num}\", \n",
    "                      'attacker_loc': attack_loc,\n",
    "                      'a_type': \"A\"\n",
    "                     }\n",
    "\n",
    "        arl_model = TrainingSetup(data_prep, log=train_log.info)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        arl_model.build(load_path = attack_path, \n",
    "                        d_loc = attack_dict['attacker_loc'],\n",
    "                        public_flag = False, \n",
    "                        privacy_flag = True, \n",
    "                        is_attack=True\n",
    "                       )\n",
    "\n",
    "        _, experiment_time = create_dir()\n",
    "        write_doc(f\"{today}-{experiment_time}\", mode=\"attack\", dictionary=attack_dict)\n",
    "\n",
    "        arl_model.attack(data_prep.train_loader_attack, \n",
    "                         data_prep.val_loader_attack,\n",
    "                         attacker_loc = attack_dict['attacker_loc'],\n",
    "                         verbose=True, \n",
    "                         val_epoch=5,\n",
    "                         previous_model = attack_dict['attack_model'],\n",
    "                         skip_train=False\n",
    "                       )\n",
    "        \n",
    "        write_doc_end(f\"{today}-{experiment_time}\", mode=\"attack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnP1mPO0rrI3"
   },
   "source": [
    "Trainformation Explanation: https://hellozhaozheng.github.io/z_post/PyTorch-SSD-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dt68hlT8W7c"
   },
   "source": [
    "# mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPYgYvZzV01A"
   },
   "source": [
    "https://drive.google.com/drive/u/1/folders/1trRWtHV_io4EDScepki1Q1RS_YewKdTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yguD56CpxpmC"
   },
   "outputs": [],
   "source": [
    "from vision.utils import box_utils\n",
    "from vision.ssd.data_preprocessing import PredictionTransform\n",
    "from vision.utils.misc import Timer\n",
    "    \n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, net, size, mean=0.0, std=1.0, nms_method=None,\n",
    "                 iou_threshold=0.45, filter_threshold=0.01, candidate_size=200, sigma=0.5, device=None):\n",
    "        self.net = net\n",
    "        self.transform = PredictionTransform(size, mean, std)\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.filter_threshold = filter_threshold\n",
    "        self.candidate_size = candidate_size\n",
    "        self.nms_method = nms_method\n",
    "\n",
    "        self.sigma = sigma\n",
    "        if device:\n",
    "            self.device = device\n",
    "        else:\n",
    "            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.net.to(self.device)\n",
    "        self.net.eval()\n",
    "\n",
    "        self.timer = Timer()\n",
    "        \n",
    "    def image_transform(self, image):\n",
    "        image = self.transform(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        image = image.to(self.device)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def predict(self, image, cnt, discriminator_loc, top_k=-1, prob_threshold=None):\n",
    "\n",
    "        #  Transforme the image. The input is only one image\n",
    "        cpu_device = torch.device(\"cpu\")\n",
    "        height, width, _ = image.shape\n",
    "        image = self.transform(image)\n",
    "        images = image.unsqueeze(0)\n",
    "        images = images.to(self.device)\n",
    "        \n",
    "        #  Feedfoward the image into the network\n",
    "        with torch.no_grad():\n",
    "            self.timer.start()\n",
    "            scores, boxes, _ = self.net(images, discriminator_loc)\n",
    "            if cnt % 100 == 0:\n",
    "                print(\"Inference time: {:4f} seconds.\".format(self.timer.end()), end='   ')\n",
    "\n",
    "        #  There is only one image. Because the output of the network is a batch of size of 1, get rid of the batch bracket\n",
    "        boxes = boxes[0]  # size = [1,3000,4]\n",
    "        scores = scores[0]  # size = [1,3000,21]\n",
    "        if not prob_threshold:\n",
    "            prob_threshold = self.filter_threshold\n",
    "\n",
    "        # this version of nms is slower on GPU, so we move data to CPU.\n",
    "        boxes = boxes.to(cpu_device)\n",
    "        scores = scores.to(cpu_device)\n",
    "        picked_box_probs = []\n",
    "        picked_labels = []\n",
    "\n",
    "        #  Inference class by class. \n",
    "        for class_index in range(1, scores.size(1)):\n",
    "            \n",
    "            #  Confidence\n",
    "            probs = scores[:, class_index]\n",
    "            mask = probs > prob_threshold # select the probability that is larger than threshold\n",
    "            probs = probs[mask]\n",
    "            if probs.size(0) == 0:\n",
    "                continue\n",
    "            \n",
    "            #  Locations\n",
    "            subset_boxes = boxes[mask, :] # select the box that has the label with probability larger than threshold. subset_boxes = [n,4]\n",
    "            box_probs = torch.cat([subset_boxes, probs.reshape(-1, 1)], dim=1)      # box_probs = [n, 4+1]\n",
    "            \n",
    "            \"\"\"TO BE UNDERSTOOD: WHAT DOES NMS DO?\"\"\"\n",
    "            box_probs = box_utils.nms(box_probs, self.nms_method,\n",
    "                                      score_threshold=prob_threshold,\n",
    "                                      iou_threshold=self.iou_threshold,\n",
    "                                      sigma=self.sigma,\n",
    "                                      top_k=top_k,\n",
    "                                      candidate_size=self.candidate_size)\n",
    "            \n",
    "            #  append the results\n",
    "            picked_box_probs.append(box_probs)\n",
    "            picked_labels.extend([class_index] * box_probs.size(0))\n",
    "\n",
    "        #  If the picked boxes are not empty, the boxes are transformed to the absolute coordinate        \n",
    "        if not picked_box_probs:\n",
    "            return torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
    "        picked_box_probs = torch.cat(picked_box_probs)\n",
    "        picked_box_probs[:, 0] *= width\n",
    "        picked_box_probs[:, 1] *= height\n",
    "        picked_box_probs[:, 2] *= width\n",
    "        picked_box_probs[:, 3] *= height\n",
    "        return picked_box_probs[:, :4], torch.tensor(picked_labels), picked_box_probs[:, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.utils import box_utils, measurements\n",
    "\n",
    "class Inference_ARL:\n",
    "    \n",
    "    def __init__(self, to_log=True, log=print):\n",
    "        self.dataset = VOCDataset('/home/hjchris/data/Pascal_VOC/VOC2007/', is_test=True) # just 2007 test\n",
    "        self.true_case_stat, self.all_gb_boxes, self.all_difficult_cases = self.group_annotation_by_class(self.dataset)\n",
    "        self.iou_threshold = 0.5\n",
    "        self.use_2007_metric = True\n",
    "        self.to_log = to_log\n",
    "        self.log = log\n",
    "        \n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.images = torch.zeros(0, 0, 0)\n",
    "        self.boxes = torch.zeros(0, 0, 0)\n",
    "        self.labels = torch.zeros(0, dtype=torch.long)\n",
    "        self.moduler_labels = torch.zeros(0, dtype=torch.long)\n",
    "        \n",
    "        self.entropy_loss = EntropyLoss()\n",
    "        self.softmaxlayer = nn.Softmax(dim=1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.nll_loss = nn.NLLLoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "        if self.use_cuda:\n",
    "            self.images=self.images.cuda()\n",
    "            self.boxes=self.boxes.cuda()\n",
    "            self.labels=self.labels.cuda()\n",
    "            self.moduler_labels = self.moduler_labels.cuda()\n",
    "    \n",
    "#     def create_handler(self, log_dir):\n",
    "#         file_item=1\n",
    "#         logging_filename = f\"({today}-{file_item}).log\"\n",
    "\n",
    "#         if not os.path.isdir(log_dir):\n",
    "#             os.mkdir(log_dir)\n",
    "#             print(f\"Created directory: {log_dir}\")\n",
    "\n",
    "#         while os.path.exists(os.path.join(log_dir, logging_filename)):\n",
    "#             file_item += 1\n",
    "#             logging_filename = f\"{today}-{file_item}.log\"\n",
    "\n",
    "#         print(f\"Log File = {log_dir}/{logging_filename}\")\n",
    "    \n",
    "#         if self.logging.hasHandlers(): self.logging.removeHandler(inf_arl.fileHandler)\n",
    "#         self.fileHandler=logging.FileHandler(\"{0}/{1}\".format(log_dir, logging_filename))\n",
    "#         self.fileHandler.setFormatter(logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\" ))\n",
    "#         self.logging.addHandler(self.fileHandler)\n",
    "\n",
    "    def load_ssd(self, ssd_path):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        label_file = os.path.join('/home/hjchris/data/Pascal_VOC/VOC2007/', \"voc-model-labels.txt\")\n",
    "        \n",
    "        self.class_names = [name.strip() for name in open(label_file).readlines()]\n",
    "       \n",
    "        self.log(f\"=\"*45 + f\" Inference Session \" + f\"=\"*45)\n",
    "        create_net = create_mobilenetv2_ssd_lite(len(self.class_names), is_test=True)\n",
    "        \n",
    "        self.net = create_net.create_SSD()\n",
    "        self.net.init_from_pretrained_ssd(ssd_path, log=self.log)\n",
    "        \n",
    "        self.load_checkpoint(ssd_path)   \n",
    "        self.predictor = create_mobilenetv2_ssd_lite_predictor(self.net, nms_method='hard', device=DEVICE)\n",
    "    \n",
    "    def load_checkpoint(self, ssd_path):\n",
    "        print(\"Load checkpoint\")\n",
    "        self.ckpt = torch.load(ssd_path, map_location=lambda storage, loc: storage)\n",
    "        self.epoch = self.ckpt['epoch']\n",
    "        self.max_grad_norm = self.ckpt['max_grad_norm']\n",
    "        self.loss = self.ckpt['loss']\n",
    "        self.privacy_flag = self.ckpt['privacy_flag']\n",
    "        self.public_flag = self.ckpt['public_flag']\n",
    "        self.discriminator_loc = -10\n",
    "        \n",
    "#         self.log(f\"Epoch={self.epoch}, max_grad norm={self.max_grad_norm}, Loss={self.ckpt['loss']:.4f}\")    \n",
    "        self.log(f\"Epoch={self.epoch}, max_grad norm={self.max_grad_norm}, Loss={self.ckpt['loss']:.4f}\")\n",
    "        \n",
    "        if self.privacy_flag:\n",
    "            \n",
    "            self.discriminator_loc = self.ckpt['discriminator_loc'] if not \"Attack\" in ssd_path else self.ckpt['attacker_loc']\n",
    "            self.sensitive_classes = self.ckpt['sensitive_classes']\n",
    "            self.arl_setting = self.ckpt['arl_setting'] if not \"Attack\" in ssd_path else \"attack\"\n",
    "        \n",
    "            total_loss = self.ckpt['total_loss'] if 'tota_loss' in self.ckpt.keys() else self.ckpt['loss']\n",
    "            self.log(f\"alpha={self.ckpt['alpha'][0]}, Sensitive Classes={self.ckpt['sensitive_classes']}, Total Loss={total_loss:.4f}, \"+ \n",
    "                    f\"Method={self.arl_setting}\")\n",
    "        \n",
    "        if self.public_flag:\n",
    "            self.public_classes = self.ckpt['public_classes']\n",
    "            self.log(f\"Public classes={self.public_classes}\")\n",
    "        \n",
    "        \n",
    "    def group_annotation_by_class(self, dataset):\n",
    "            true_case_stat = {}\n",
    "            all_gt_boxes = {}\n",
    "            all_difficult_cases = {}\n",
    "            \n",
    "            for i in range(len(dataset)):\n",
    "                image_id, annotation = dataset.get_annotation(i)\n",
    "                gt_boxes, classes, is_difficult = annotation\n",
    "                gt_boxes = torch.from_numpy(gt_boxes)\n",
    "                for i, difficult in enumerate(is_difficult):\n",
    "                    class_index = int(classes[i])\n",
    "                    gt_box = gt_boxes[i]\n",
    "                    if not difficult:\n",
    "                        true_case_stat[class_index] = true_case_stat.get(class_index, 0) + 1\n",
    "\n",
    "                    if class_index not in all_gt_boxes:\n",
    "                        all_gt_boxes[class_index] = {}\n",
    "                    if image_id not in all_gt_boxes[class_index]:\n",
    "                        all_gt_boxes[class_index][image_id] = []\n",
    "                    all_gt_boxes[class_index][image_id].append(gt_box)\n",
    "                    if class_index not in all_difficult_cases:\n",
    "                        all_difficult_cases[class_index]={}\n",
    "                    if image_id not in all_difficult_cases[class_index]:\n",
    "                        all_difficult_cases[class_index][image_id] = []\n",
    "                    all_difficult_cases[class_index][image_id].append(difficult)\n",
    "\n",
    "            for class_index in all_gt_boxes:\n",
    "                for image_id in all_gt_boxes[class_index]:\n",
    "                    all_gt_boxes[class_index][image_id] = torch.stack(all_gt_boxes[class_index][image_id])\n",
    "            for class_index in all_difficult_cases:\n",
    "                for image_id in all_difficult_cases[class_index]:\n",
    "                    all_gt_boxes[class_index][image_id] = all_gt_boxes[class_index][image_id].clone().detach()\n",
    "            return true_case_stat, all_gt_boxes, all_difficult_cases\n",
    "        \n",
    "    def compute_average_precision_per_class(self, num_true_cases, gt_boxes, difficult_cases,\n",
    "                                        prediction_file, iou_threshold, use_2007_metric):\n",
    "        \n",
    "         #  Read the files one by one. Each file is one class\n",
    "        with open(prediction_file) as f:\n",
    "            image_ids = []\n",
    "            boxes = []\n",
    "            scores = []\n",
    "            \n",
    "            #  Read the lines. Format: image_id, confidence, 4 coordinates\n",
    "            for line in f:\n",
    "                t = line.rstrip().split(\" \")\n",
    "                image_ids.append(t[0])\n",
    "                scores.append(float(t[1]))\n",
    "                box = torch.tensor([float(v) for v in t[2:]]).unsqueeze(0)\n",
    "                box -= 1.0  # convert to python format where indexes start from 0\n",
    "                boxes.append(box)\n",
    "                \n",
    "            scores = np.array(scores)\n",
    "            \n",
    "            #  Inverse indexes. Smallest confidence in the front.\n",
    "            sorted_indexes = np.argsort(-scores)\n",
    "            boxes = [boxes[i] for i in sorted_indexes]\n",
    "            image_ids = [image_ids[i] for i in sorted_indexes]\n",
    "            \n",
    "            #  len(image_ids) = number of boxes predicted as this class in the whole dataset. \n",
    "            true_positive = np.zeros(len(image_ids))\n",
    "            false_positive = np.zeros(len(image_ids))\n",
    "            matched = set()\n",
    "            \n",
    "             #  Calculate true_positive and false_positive for each box.\n",
    "            for i, image_id in enumerate(image_ids):\n",
    "                box = boxes[i]\n",
    "                \n",
    "                # if the image is not in the sets --> this prediction is false\n",
    "                if image_id not in gt_boxes:\n",
    "                    false_positive[i] = 1\n",
    "                    continue\n",
    "\n",
    "                gt_box = gt_boxes[image_id]\n",
    "                ious = box_utils.iou_of(box, gt_box)\n",
    "                max_iou = torch.max(ious).item()\n",
    "                max_arg = torch.argmax(ious).item()\n",
    "                \n",
    "                # if the iou is larger enough:\n",
    "                if max_iou > iou_threshold:\n",
    "                    \n",
    "                    # if it is not a difficult case:\n",
    "                    if difficult_cases[image_id][max_arg] == 0:\n",
    "                        \n",
    "                        # if the ground truth box has not been predicted --> true prediction.\n",
    "                        if (image_id, max_arg) not in matched:\n",
    "                            true_positive[i] = 1\n",
    "                            matched.add((image_id, max_arg))\n",
    "                            \n",
    "                        # if the the ground truth box is already predicted --> false prediction.\n",
    "                        else:\n",
    "                            false_positive[i] = 1\n",
    "                \n",
    "                # if the iou is smaller than 0.5 --> consider ths prediction is false.\n",
    "                else:\n",
    "                    false_positive[i] = 1\n",
    "\n",
    "        true_positive = true_positive.cumsum()\n",
    "        false_positive = false_positive.cumsum()\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / num_true_cases\n",
    "        \n",
    "        # It computes the under curve area of precision and recall. Recall follows the normal definition. Precision is a variant.\n",
    "        if use_2007_metric:\n",
    "            return measurements.compute_voc2007_average_precision(precision, recall)\n",
    "        else:\n",
    "            return measurements.compute_average_precision(precision, recall)\n",
    "   \n",
    "    def write_results(self, eval_path, discriminator_loc):\n",
    "        timer = Timer()\n",
    "        results = []\n",
    "        for i in range(len(self.dataset)):\n",
    "            timer.start(\"Load Image\")\n",
    "            image = self.dataset.get_image(i)\n",
    "            if i%100 == 0: print(f\"[{i:4d}]\"+ \"Load Image: {:4f} seconds.\".format(timer.end(\"Load Image\")), end=' ')\n",
    "            timer.start(\"Predict\")\n",
    "            boxes, labels, probs = self.predictor.predict(image, i, discriminator_loc)\n",
    "            if i%100 == 0:print(\"Prediction: {:4f} seconds.\".format(timer.end(\"Predict\")))\n",
    "            indexes = torch.ones(labels.size(0), 1, dtype=torch.float32) * i\n",
    "            results.append(torch.cat([\n",
    "                indexes.reshape(-1, 1),\n",
    "                labels.reshape(-1, 1).float(),\n",
    "                probs.reshape(-1, 1),\n",
    "                boxes + 1.0  # matlab's indexes start from 1\n",
    "            ], dim=1))\n",
    "            \n",
    "        results = torch.cat(results)\n",
    "        \n",
    "        for class_index, class_name in enumerate(self.class_names):\n",
    "            if class_index == 0: \n",
    "                continue  # ignore background\n",
    "            \n",
    "            prediction_path = eval_path + f\"det_test_{class_name}.txt\"\n",
    "            \n",
    "            with open(prediction_path, \"w\") as f:\n",
    "                sub = results[results[:, 1] == class_index, :]\n",
    "                for i in range(sub.size(0)):\n",
    "                    prob_box = sub[i, 2:].numpy()\n",
    "                    image_id = self.dataset.ids[int(sub[i, 0])]\n",
    "                    print(\n",
    "                        image_id + \" \" + \" \".join([str(v) for v in prob_box]),\n",
    "                        file=f\n",
    "                    )\n",
    "\n",
    "    def inference_ssd(self, eval_path):  \n",
    "        ''' =====================================================================\n",
    "        Inference encoder and decoder.\n",
    "            1. \n",
    "            2. \n",
    "        ===================================================================== '''        \n",
    "        \n",
    "        self.log(f\"Results are stored at {eval_path}\")        \n",
    "       \n",
    "        # Run results\n",
    "        count_files = len([name for name in os.listdir(eval_path) if os.path.isfile(os.path.join(eval_path, name))])\n",
    "        if count_files != 20: \n",
    "            print(\"Write Files.\")\n",
    "            self.write_results(eval_path, self.discriminator_loc)\n",
    "        \n",
    "        # Read results\n",
    "        aps = []\n",
    "        self.log(\"Average Precision Per-class:\")\n",
    "            \n",
    "        for class_index, class_name in enumerate(self.class_names):\n",
    "            if class_index == 0:\n",
    "                continue\n",
    "                \n",
    "            prediction_path = eval_path + f\"det_test_{class_name}.txt\"\n",
    "            ap = self.compute_average_precision_per_class(\n",
    "                self.true_case_stat[class_index],\n",
    "                self.all_gb_boxes[class_index],\n",
    "                self.all_difficult_cases[class_index],\n",
    "                prediction_path,\n",
    "                self.iou_threshold,\n",
    "                self.use_2007_metric\n",
    "            )\n",
    "            aps.append(ap)\n",
    "            self.log(f\"{class_name}: {ap}\")\n",
    "                \n",
    "        self.log(f\"Average Precision Across All Classes:{sum(aps)/len(aps)}\")\n",
    "        \n",
    "    def load_moduler(self, ssd_path, module=\"discriminator\", size=300, mean=0.0, std=1.0, verbose=False):\n",
    "        self.log(f\"Load {module}.\")\n",
    "        \n",
    "        self.transform = PredictionTransform(size, mean, std)\n",
    "        create_discriminator = Create_Discriminator()\n",
    "        \n",
    "        # need update\n",
    "        if module == \"discriminator\":\n",
    "            self.discriminator_loc = self.ckpt['discriminator_loc'] \n",
    "        elif module == \"attacker\":\n",
    "            self.discriminator_loc = self.ckpt['attacker_loc']\n",
    "        elif module == \"public\": \n",
    "            self.discriminator_loc = self.ckpt['discriminator_loc']\n",
    "        else:\n",
    "            raise Exception(f\"Only discriminator, attacker, or public.\")\n",
    "            \n",
    "        self.moduler = create_discriminator.build(self.discriminator_loc)\n",
    "        self.moduler.load(ssd_path, module = module)\n",
    "            \n",
    "    def online_sensitive_labels(self, labels, classes=[15]):\n",
    "        temp = torch.zeros(len(labels), dtype=torch.long)\n",
    "        for j in range(len(temp)):\n",
    "            temp[j] = (1 if any(items in labels[j].unique() for items in classes) else 0)   \n",
    "        return temp\n",
    "    \n",
    "    def image_transform(self, image):\n",
    "        image = self.transform(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        image = image.to(self.device)\n",
    "        return image\n",
    "    \n",
    "    def inference_moduler(self, val_loader, module, print_every=5):\n",
    "        self.log(f\"Inference {module}.\")\n",
    "            \n",
    "        if module == \"attacker\" or module == \"discriminator\":\n",
    "            module_classes = self.ckpt['sensitive_classes']\n",
    "        elif module == \"public\":\n",
    "            module_classes = self.ckpt['public_classes']\n",
    "        else:\n",
    "            raise Exception(f\"Only attacker, discriminator, or public.\")\n",
    "            \n",
    "        config = mobilenetv1_ssd_config\n",
    "        criterion = MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3, center_variance=0.1, size_variance=0.2, device=DEVICE)\n",
    "        \n",
    "        self.net.eval()\n",
    "        self.moduler.eval()\n",
    "        timer = Timer()\n",
    "        train_correct = 0.0\n",
    "        loss = 0.0\n",
    "        num = 0\n",
    "        check = 0\n",
    "        TP, TN, FP, FN = 0, 0, 0, 0\n",
    "        timer.start(\"Inference Image\")\n",
    "        itr = 0\n",
    "\n",
    "        for (i, data) in enumerate(val_loader):\n",
    "            \n",
    "            itr += 1\n",
    "\n",
    "#             self.image = self.image_transform(data[0])\n",
    "            \n",
    "#             labels = torch.from_numpy(data[2].reshape(1, -1))        \n",
    "#             self.labels.resize_(labels.size()).copy_(labels)\n",
    "\n",
    "            \n",
    "#             sensitive_labels = data[3] if len(data) == 4 else self.online_sensitive_labels(self.labels, self.ssd_ckpt['sensitive_classes'])\n",
    "#             self.sensitive_labels.resize_(sensitive_labels.size()).copy_(sensitive_labels)  \n",
    "            \n",
    "            self.images.resize_(data[0].size()).copy_(data[0])\n",
    "            self.labels.resize_(data[2].size()).copy_(data[2])\n",
    "            sensitive_labels = data[3] if len(data) == 4 else self.online_sensitive_labels(self.labels, module_classes)\n",
    "            self.moduler_labels.resize_(sensitive_labels.size()).copy_(sensitive_labels)     \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                _, _, z = self.net(self.images, self.discriminator_loc)\n",
    "                z = self.moduler(z)\n",
    "\n",
    "                d_prob = F.softmax(z, dim=1)\n",
    "                loss += self.nll_loss(torch.log(d_prob+1e-16), self.moduler_labels)\n",
    "            \n",
    "            probability, indecies = torch.max(d_prob, dim=1)\n",
    "            train_correct += np.sum(np.array(self.moduler_labels.cpu())==np.array(indecies.cpu()))\n",
    "            num += indecies.size()[0]\n",
    "\n",
    "            # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n",
    "            TP += torch.sum(torch.logical_and(torch.unsqueeze(indecies,0) == 1, torch.unsqueeze(self.moduler_labels,0) == 1))\n",
    "\n",
    "            # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "            TN += torch.sum(torch.logical_and(torch.unsqueeze(indecies,0) == 0, torch.unsqueeze(self.moduler_labels,0) == 0))\n",
    "\n",
    "            # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "            FP += torch.sum(torch.logical_and(torch.unsqueeze(indecies,0) == 1, torch.unsqueeze(self.moduler_labels,0) == 0))\n",
    "\n",
    "            # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "            FN += torch.sum(torch.logical_and(torch.unsqueeze(indecies,0) == 0, torch.unsqueeze(self.moduler_labels,0) == 1))\n",
    "\n",
    "            check += torch.sum(self.moduler_labels == 1) \n",
    "            \n",
    "            if itr % print_every == 0: \n",
    "                print(f\"[{itr:4d}][{num:4d}] \" + \"Inference: {:4f}s.\".format(timer.end(\"Inference Image\")) + \n",
    "                      f\"Accuracy = {float(train_correct/num):4f}, Loss = {float(loss/itr):.4f}, \" + \n",
    "                      f\"[TP = {float(TP)/num*100:.2f}%, FN = {float(FN)/num*100:.2f}%, TN = {float(TN)/num*100:.2f}%, FP = {float(FP)/num*100:.2f}%]\")\n",
    "                timer.start(\"Inference Image\")\n",
    "\n",
    "        timer.end(\"Inference Image\")\n",
    "        \n",
    "        self.log(f\"{module} Loss = {float(loss/itr):.4f}. {module} Accuracy = {train_correct/num}\")\n",
    "        self.log(f\"TP={float(TP)/num*100:.2f}%, FN={float(FN)/num*100:2.2f}%, \" +  \n",
    "                          f\"TN={float(TN)/num*100:2.2f}%, FP={float(FP)/num*100:2.2f}%, Total Images={num}, 1={check}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Handler(log, log_dir, path_name):\n",
    "    file_item=1\n",
    "    logging_filename = f\"{path_name} ({today}-{file_item}).log\"\n",
    "\n",
    "    if not os.path.isdir(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "        print(f\"Created directory: {log_dir}\")\n",
    "\n",
    "    while os.path.exists(os.path.join(log_dir, logging_filename)):\n",
    "        file_item += 1\n",
    "        logging_filename = f\"{path_name} ({today}-{file_item}).log\"\n",
    "\n",
    "    print(f\"Log File = {log_dir}/{logging_filename}\")\n",
    "\n",
    "    if log.hasHandlers(): \n",
    "        log.removeHandler(inf_fileHandler)\n",
    "        log.removeHandler(streamHandler)\n",
    "    \n",
    "    fileHandler = logging.FileHandler(\"{0}/{1}\".format(log_dir, logging_filename))\n",
    "    fileHandler.setFormatter(logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\" ))\n",
    "    \n",
    "    log.addHandler(fileHandler)\n",
    "    log.addHandler(streamHandler)\n",
    "    \n",
    "    return fileHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_date = 1229\n",
    "exp_nums = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "\n",
    "for exp_num in exp_nums:\n",
    "    ssd_path, eval_path = find_ssd_file('/home/hjchris/research/mitigating/chris/pascal_ckpts/' + f\"{inference_date}_21/{str(inference_date)}_21-{str(exp_num)}/\")\n",
    "\n",
    "    to_log = True\n",
    "    if to_log: inf_fileHandler = create_Handler(inf_log, log_dir, ssd_path[61:70])\n",
    "    inf_arl = Inference_ARL(to_log=to_log, log=inf_log.info)\n",
    "    inf_arl.load_ssd(ssd_path)\n",
    "    inf_arl.inference_ssd(eval_path)\n",
    "\n",
    "    data_path = f\"/home/hjchris/data\"\n",
    "    data_prep = Data_Preprocessing()\n",
    "    data_prep.load_online(data_path)\n",
    "\n",
    "    if \"Attack\" in ssd_path:\n",
    "        inf_arl.load_moduler(ssd_path, module=\"attacker\")\n",
    "        inf_arl.inference_moduler(data_prep.val_loader, module=\"attacker\")\n",
    "    elif \"FM\" in ssd_path:\n",
    "        if inf_arl.privacy_flag:\n",
    "            #module = \"discriminator\" #public or discriminator\n",
    "            inf_arl.load_moduler(ssd_path, module=\"discriminator\")\n",
    "            inf_arl.inference_moduler(data_prep.val_loader, module=\"discriminator\")\n",
    "        if inf_arl.public_flag:\n",
    "            inf_arl.load_moduler(ssd_path, module=\"public\")\n",
    "            inf_arl.inference_moduler(data_prep.val_loader, module=\"public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgE91Cww33vb"
   },
   "source": [
    "The reason that average precision is nan is that when the difficult cases == 1.\n",
    "\n",
    "`difficult': an object marked as `difficult' indicates that the object is considered difficult to recognize, for example an object which is clearly visible but unidentifiable without substantial use of context. Objects marked as **difficult are currently ignored** in the evaluation of the challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Precision Per-class:\n",
    "\n",
    "aeroplane: 0.6973327307871002\n",
    "\n",
    "bicycle: 0.7823755921687233\n",
    "\n",
    "bird: 0.6342429230125619\n",
    "\n",
    "boat: 0.5478160937380846\n",
    "\n",
    "bottle: 0.3564069147093762\n",
    "\n",
    "bus: 0.7882037885117419\n",
    "\n",
    "car: 0.7444122242934775\n",
    "\n",
    "cat: 0.8198865557991936\n",
    "\n",
    "chair: 0.5378973422880109\n",
    "\n",
    "cow: 0.6186076149254742\n",
    "\n",
    "diningtable: 0.7369559500950861\n",
    "\n",
    "dog: 0.7848265495754562\n",
    "\n",
    "horse: 0.8222948787839229\n",
    "\n",
    "motorbike: 0.8057808854619948\n",
    "\n",
    "person: 0.7176976451996411\n",
    "\n",
    "pottedplant: 0.42802932547480066\n",
    "\n",
    "sheep: 0.6259124005994047\n",
    "\n",
    "sofa: 0.7840368059271103\n",
    "\n",
    "train: 0.8331588002612781\n",
    "\n",
    "tvmonitor: 0.6555051795079904\n",
    "\n",
    "Average Precision Across All Classes:0.6860690100560214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_path = f\"/home/hjchris/research/mitigating/chris/pascal_ckpts/1229_21/1229_21-8/mb2-ssd-lite-Attack-Ep200-FM21-Loss-2.8964+0.3243-Ent-0.3584.pth\"\n",
    "ckpt = torch.load(ssd_path, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['attacked_model']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DcALbJAb8-wQ"
   ],
   "machine_shape": "hm",
   "name": "2021Oct_Pascal_MBNv2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233.125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
